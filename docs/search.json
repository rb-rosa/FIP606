[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FIP606",
    "section": "",
    "text": "AUTOR\nRaphael B Rosa"
  },
  {
    "objectID": "index.html#bem-vindo",
    "href": "index.html#bem-vindo",
    "title": "FIP606",
    "section": "Bem-vindo",
    "text": "Bem-vindo\n\nEste é o Quarto website para disponibilizar as aulas em RStudio sobre Análise e Visualização de Dados em Fitopatologia da disciplina FIP 606, oferecida no Programa de Pós-graduação em Fitopatologia da Universidade Federal de Viçosa pelo professor Emerson M Del Ponte. As aulas são códigos comentados e estão organizadas em “Fundamentos”, “Análise Exploratória” e “Análise de Dados”. O objetivo do website é compartilhar o conhecimento aprendido com outros colegas da área e despertar o interesse daqueles que ainda não conhecem o tema.\n\nEspero que aproveite!\n\nPara mais informações sobre ciência de dados no R, clique aqui."
  },
  {
    "objectID": "R_codes/aula1.html",
    "href": "R_codes/aula1.html",
    "title": "Quarto",
    "section": "",
    "text": "Aula 1\nPermite que você junte conteúdo e código executável em um documento finalizado. Para saber mais sobre Quarto veja https://quarto.org."
  },
  {
    "objectID": "R_codes/aula1.html#código-em-execução",
    "href": "R_codes/aula1.html#código-em-execução",
    "title": "Quarto",
    "section": "Código em execução",
    "text": "Código em execução\nAo clicar no botão Renderizar, será gerado um documento que inclui o conteúdo e a saída do código incorporado. Você pode incorporar código como este:\n\n1 + 1\n\n[1] 2\n\n\nVocê pode adicionar opções ao código executável como este\n\n2 * 2\n\n[1] 4"
  },
  {
    "objectID": "R_codes/aula1.html#ocultar-código-fonte",
    "href": "R_codes/aula1.html#ocultar-código-fonte",
    "title": "Quarto",
    "section": "Ocultar código fonte",
    "text": "Ocultar código fonte\nUsar {r, echo=FALSE} oculta o código 2 * 2.\n\n\n[1] 4"
  },
  {
    "objectID": "R_codes/aula10.html",
    "href": "R_codes/aula10.html",
    "title": "1 Fator",
    "section": "",
    "text": "Aula 10"
  },
  {
    "objectID": "R_codes/aula10.html#três-ou-mais-tratamentos",
    "href": "R_codes/aula10.html#três-ou-mais-tratamentos",
    "title": "1 Fator",
    "section": "Três ou mais tratamentos",
    "text": "Três ou mais tratamentos\nANOVA é feita para níveis categóricos (fator qualitativo). Na ANOVA, queremos saber quem é diferente de quem.\nExperimento com um fator e em delineamento inteiramente casualizado para comparar o crescimento micelial de diferentes espécies de um fungo fitopatogênico. A resposta a ser estudada é a TCM = taxa de crescimento micelial."
  },
  {
    "objectID": "R_codes/aula10.html#preparo",
    "href": "R_codes/aula10.html#preparo",
    "title": "1 Fator",
    "section": "Preparo",
    "text": "Preparo\n\nlibrary(readxl)\nlibrary(tidyverse)\nmicelial <- read_excel(\"dados-diversos.xlsx\", \"micelial\")\nhead (micelial)\n\n# A tibble: 6 × 3\n  especie   rep   tcm\n  <chr>   <dbl> <dbl>\n1 Fasi        1  1.5 \n2 Fasi        2  1.59\n3 Fasi        3  1.52\n4 Fasi        4  1.52\n5 Fasi        5  1.24\n6 Fasi        6  1.29\n\n\n\nmicelial|> \n  ggplot(aes(especie, tcm)) +\n  geom_boxplot()"
  },
  {
    "objectID": "R_codes/aula10.html#ajustar-o-modelo-usando-aov",
    "href": "R_codes/aula10.html#ajustar-o-modelo-usando-aov",
    "title": "1 Fator",
    "section": "Ajustar o modelo usando aov()",
    "text": "Ajustar o modelo usando aov()\n\n#Ajustar o modelo\n# <- (atribuiu aov a aov1); ~ (em função de); aov (função ANOVA)\naov1 <- aov(tcm ~ especie, data = micelial)\nsummary(aov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nespecie      4 0.4692 0.11729   1.983  0.117\nResiduals   37 2.1885 0.05915               \n\n#Não há efeito significativo de espécie P=0.117."
  },
  {
    "objectID": "R_codes/aula10.html#testar-as-premissas",
    "href": "R_codes/aula10.html#testar-as-premissas",
    "title": "1 Fator",
    "section": "Testar as premissas",
    "text": "Testar as premissas\nOs prossupostos da ANOVA são normalidade e a homocedasticidade dos dados. Se são normais e apresentam igualdade de variâncias, então pode se realizar ANOVA. Se os dados não forem normais e não apresentarem igualdade, pode-se fazer a transformação dos dados, se não funcionar, utilizar modelos não paramétricos, se não, usar modelo linear generalizao (GLM) ou outros. Falta de homocedasticidade não é tolerável, de normalidade, sim.\n\n#Checar as premissas para verificar se o modelo está correto\nlibrary(performance)\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.175).\n\n#Resultado: OK. Error variance appears to be homoscedastic (p = 0.175). Significa que as variâncias são homogeneas.Se o p-valor for < 0.05 indica que os dados não são homogeneos.\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.074).\n\n#OK: residuals appear as normally distributed (p = 0.074). Significa que há normalidade. Se o p-valor for < 0.05 indica que os dados não apresentam normalidade.\nlibrary(DHARMa)\nplot(simulateResiduals(aov1))\n\n\n\n#Normalidade a esquerda e variância homogenea a direita\n# teste de normalidade\nhist(aov1$residuals)\n\n\n\nqqnorm(aov1$residuals)\nqqline(aov1$residuals)\n\n\n\nshapiro.test(aov1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  aov1$residuals\nW = 0.95101, p-value = 0.07022"
  },
  {
    "objectID": "R_codes/aula10.html#e-quando-não-atende-às-premissas",
    "href": "R_codes/aula10.html#e-quando-não-atende-às-premissas",
    "title": "1 Fator",
    "section": "E quando não atende às premissas?",
    "text": "E quando não atende às premissas?\nEfeito de inseticida na mortalidade de insetos (Beall, 1942). The Transformation of data from entomological field experiments, Biometrika, 29, 243–262. Dados no pacote “datasets” do R. data(InsectSprays)\n\n# criando o objeto insects\ninsects <- tibble::as_tibble(InsectSprays) |> \n  dplyr::select(spray, count)\ninsects\n\n# A tibble: 72 × 2\n   spray count\n   <fct> <dbl>\n 1 A        10\n 2 A         7\n 3 A        20\n 4 A        14\n 5 A        14\n 6 A        12\n 7 A        10\n 8 A        23\n 9 A        17\n10 A        20\n# ℹ 62 more rows\n\n\n\ninsects|> \n  ggplot(aes(spray, count)) +\n  geom_boxplot()\n\n\n\n\n\naov1 <- aov(count ~ spray, data = insects)\nsummary(aov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5   2669   533.8    34.7 <2e-16 ***\nResiduals   66   1015    15.4                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\n#OK: Error variance appears to be homoscedastic (p = 0.175). Significa que as variâncias não são homogeneas, p < 0.05.\n\n\n# nesse caso, recomenda-se transformar os dados para atender as premissas e então utilizar a ANOVA. Se as transformações não atenderem a homocedasticidade, utilizar teste não paramétrico.\n# alternativa 1: transformar dados originais, se for números. Usar raiz quadrada ou logaritimo\n# sqrt:  raiz quadrada\n# log: logarítimo. se houver valor zero no \"count\" somar 0.5.\naov2 <- aov(sqrt(count) ~ spray, data = insects)\n#aov2 <- aov(log(count+0.5) ~ spray, data = insects)\nsummary(aov2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5  88.44  17.688    44.8 <2e-16 ***\nResiduals   66  26.06   0.395                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_heteroscedasticity(aov2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\ncheck_normality(aov2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\n# atenteu as premissas\n\nlibrary(emmeans)\n# médias por inseticida\n# type = \"response\": para que a média não seja transformada, o inverso da raiz\naov2_means <- emmeans(aov2, ~ spray, type = \"response\")\naov2_means\n\n spray response    SE df lower.CL upper.CL\n A        14.14 1.364 66   11.550    17.00\n B        15.03 1.406 66   12.352    17.97\n C         1.55 0.452 66    0.779     2.58\n D         4.68 0.785 66    3.248     6.38\n E         3.27 0.656 66    2.095     4.72\n F        16.15 1.458 66   13.370    19.19\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale"
  },
  {
    "objectID": "R_codes/aula10.html#teste-de-tukey",
    "href": "R_codes/aula10.html#teste-de-tukey",
    "title": "1 Fator",
    "section": "Teste de Tukey",
    "text": "Teste de Tukey\n\n# comparação entre pares\npwpm(aov2_means)\n\n        A       B       C       D       E       F\nA [14.14]  0.9975  <.0001  <.0001  <.0001  0.9145\nB  -0.116 [15.03]  <.0001  <.0001  <.0001  0.9936\nC   2.516   2.632 [ 1.55]  0.0081  0.2513  <.0001\nD   1.596   1.712  -0.919 [ 4.68]  0.7366  <.0001\nE   1.951   2.067  -0.565   0.355 [ 3.27]  <.0001\nF  -0.258  -0.142  -2.774  -1.854  -2.209 [16.15]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (response)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n\n# com letras. O teste de Tukey faz uma comparação múltipla (teste de médias comun mais utilizado). Ele apresenta uma ambiguidade, por exemplo, um tratamento com duas letras, pertencendo a dois grupos.\nlibrary(multcomp)\nlibrary(multcompView)\ncld(aov2_means)\n\n spray response    SE df lower.CL upper.CL .group\n C         1.55 0.452 66    0.779     2.58  1    \n E         3.27 0.656 66    2.095     4.72  12   \n D         4.68 0.785 66    3.248     6.38   2   \n A        14.14 1.364 66   11.550    17.00    3  \n B        15.03 1.406 66   12.352    17.97    3  \n F        16.15 1.458 66   13.370    19.19    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/aula10.html#teste-não-paramétrico",
    "href": "R_codes/aula10.html#teste-não-paramétrico",
    "title": "1 Fator",
    "section": "Teste não paramétrico",
    "text": "Teste não paramétrico\n\n# teste não paramétrico, se não atendeu as premissas da ANOVA mesmo com transformção dos dados.\nkruskal.test(count ~ spray, data = insects)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nlibrary(agricolae)\nkruskal(insects$count, insects$spray, console = TRUE)\n\n\nStudy: insects$count ~ insects$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\ninsects$spray,  means of the ranks\n\n  insects.count  r\nA      52.16667 12\nB      54.83333 12\nC      11.45833 12\nD      25.58333 12\nE      19.33333 12\nF      55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  insects$count groups\nF      55.62500      a\nB      54.83333      a\nA      52.16667      a\nD      25.58333      b\nE      19.33333     bc\nC      11.45833      c"
  },
  {
    "objectID": "R_codes/aula10.html#modelo-linear-generalizado",
    "href": "R_codes/aula10.html#modelo-linear-generalizado",
    "title": "1 Fator",
    "section": "Modelo linear generalizado",
    "text": "Modelo linear generalizado\nPara publicar artigo, o modelo linear é melhor que transformar os dados originais. É mais elegante usar o glm do que transformar os dados.\n\nglm1 <- glm(count ~ spray,\n         data = insects,\n         family = poisson(link = \"identity\"))\n# poisson: adequado para dados de contagem. Muito utilizado para nematoide.\nplot(simulateResiduals(glm1))\n\n\n\n# catPred é o mais importante\nsummary(glm1)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson(link = \"identity\"), \n    data = insects)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  14.5000     1.0992  13.191  < 2e-16 ***\nsprayB        0.8333     1.5767   0.529    0.597    \nsprayC      -12.4167     1.1756 -10.562  < 2e-16 ***\nsprayD       -9.5833     1.2720  -7.534 4.92e-14 ***\nsprayE      -11.0000     1.2247  -8.981  < 2e-16 ***\nsprayF        2.1667     1.6116   1.344    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 3\n\nglm1_means <- emmeans(glm1, ~ spray)\ncld(glm1_means)\n\n spray emmean    SE  df asymp.LCL asymp.UCL .group\n C       2.08 0.417 Inf      1.27      2.90  1    \n E       3.50 0.540 Inf      2.44      4.56  12   \n D       4.92 0.640 Inf      3.66      6.17   2   \n A      14.50 1.099 Inf     12.35     16.65    3  \n B      15.33 1.130 Inf     13.12     17.55    3  \n F      16.67 1.179 Inf     14.36     18.98    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/aula11.html",
    "href": "R_codes/aula11.html",
    "title": "2 ou mais fatores",
    "section": "",
    "text": "Aula 11"
  },
  {
    "objectID": "R_codes/aula11.html#checar-premissas-comparar-médias-cv",
    "href": "R_codes/aula11.html#checar-premissas-comparar-médias-cv",
    "title": "2 ou mais fatores",
    "section": "Checar premissas, comparar médias, CV",
    "text": "Checar premissas, comparar médias, CV\n\nm1 <- aov(log(inc +0.5) ~ treat*dose,\n          data = dat2)\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value  Pr(>F)   \ntreat        1 12.928  12.928  13.980 0.00179 **\ndose         1  5.663   5.663   6.124 0.02491 * \ntreat:dose   1  5.668   5.668   6.129 0.02486 * \nResiduals   16 14.796   0.925                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.050).\n\n# p=0.050 considera-se dados normais.\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.180).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\nlibrary(emmeans)\nmeans_m1 <- emmeans(m1, ~ dose | treat,\n                    type = \"response\")\nmeans_m1\n\ntreat = Ionic liquid:\n dose response     SE df lower.CL upper.CL\n  0.5    27.05 11.847 16   10.570    68.05\n  2.0     3.10  1.412 16    1.065     7.77\n\ntreat = Tebuconazole:\n dose response     SE df lower.CL upper.CL\n  0.5     1.21  0.737 16    0.188     3.76\n  2.0     1.42  0.925 16    0.194     4.83\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \n\nlibrary(multcompView)\nlibrary(multcomp)\n# para comparar as médias.\ncld(means_m1)\n\ntreat = Ionic liquid:\n dose response     SE df lower.CL upper.CL .group\n  2.0     3.10  1.412 16    1.065     7.77  1    \n  0.5    27.05 11.847 16   10.570    68.05   2   \n\ntreat = Tebuconazole:\n dose response     SE df lower.CL upper.CL .group\n  0.5     1.21  0.737 16    0.188     3.76  1    \n  2.0     1.42  0.925 16    0.194     4.83  1    \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n# para calcular o coeficiente de variação\nlibrary(agricolae)\ncv.model(m1)\n\n[1] 65.04818\n\n\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \n                    \"armazena\")\nmilho2 <- milho |> \n  filter(tempo == 8)\n\nmilho2 |> \n  ggplot(aes(factor(tipo), peso_mil,\n             color = factor(umidade)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~umidade)\n\n\n\nm2 <- aov(peso_mil ~ factor(tipo)*factor(umidade),\n          data = milho2)\nsummary(m2)\n\n                             Df Sum Sq Mean Sq F value   Pr(>F)    \nfactor(tipo)                  1  11215   11215  2375.8 3.64e-15 ***\nfactor(umidade)               2  42814   21407  4534.8  < 2e-16 ***\nfactor(tipo):factor(umidade)  2   2329    1165   246.7 1.79e-10 ***\nResiduals                    12     57       5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "R_codes/aula11.html#sem-significância-entre-a-interação",
    "href": "R_codes/aula11.html#sem-significância-entre-a-interação",
    "title": "2 ou mais fatores",
    "section": "Sem significância entre a interação",
    "text": "Sem significância entre a interação\n\n#quando não houver significãncia entre a interação, testar as variáveis independentes.\nmilho3 <- read_excel(\"dados-diversos.xlsx\", \n                    \"milho\")\n\nm4 <- aov(yield ~ hybrid,\n          data = milho3)\nsummary(m4)\n\n            Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid       5 105876446 21175289   8.688 1.02e-05 ***\nResiduals   42 102371996  2437428                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_heteroscedasticity(m4)\n\nOK: Error variance appears to be homoscedastic (p = 0.763).\n\nplot(simulateResiduals(m4))\n\n\n\nmedias_m4 <- emmeans(m4, ~ hybrid)\nmedias_m4\n\n hybrid   emmean  SE df lower.CL upper.CL\n 30F53 HX  10598 552 42     9484    11712\n 30F53 YH   9309 552 42     8195    10423\n 30K64     11018 552 42     9904    12132\n 30S31H     8652 552 42     7538     9765\n 30S31YH    8056 552 42     6942     9170\n BG7049H   12402 552 42    11288    13516\n\nConfidence level used: 0.95 \n\n#Tuckey\ncld(medias_m4)\n\n hybrid   emmean  SE df lower.CL upper.CL .group\n 30S31YH    8056 552 42     6942     9170  1    \n 30S31H     8652 552 42     7538     9765  12   \n 30F53 YH   9309 552 42     8195    10423  123  \n 30F53 HX  10598 552 42     9484    11712   234 \n 30K64     11018 552 42     9904    12132    34 \n BG7049H   12402 552 42    11288    13516     4 \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(medias_m4)\n\n         30F53 HX 30F53 YH   30K64  30S31H 30S31YH BG7049H\n30F53 HX  [10598]   0.5709  0.9942  0.1494  0.0254  0.2125\n30F53 YH     1288  [ 9309]  0.2643  0.9576  0.5999  0.0036\n30K64        -420    -1709 [11018]  0.0447  0.0059  0.4938\n30S31H       1946      658    2366 [ 8652]  0.9723  0.0003\n30S31YH      2541     1253    2962     595 [ 8056]  <.0001\nBG7049H     -1804    -3092   -1384   -3750   -4345 [12402]\n\nRow and column labels: hybrid\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(medias_m4)"
  },
  {
    "objectID": "R_codes/aula12.html",
    "href": "R_codes/aula12.html",
    "title": "DBC",
    "section": "",
    "text": "Aula 12"
  },
  {
    "objectID": "R_codes/aula12.html#delineamento-em-blocos-casualisados",
    "href": "R_codes/aula12.html#delineamento-em-blocos-casualisados",
    "title": "DBC",
    "section": "Delineamento em blocos casualisados",
    "text": "Delineamento em blocos casualisados\n\nlibrary(readxl)\nlibrary(tidyverse)\n#delineamento em blocos casualisados\n#efeito fixo (bloco): trat + bloco\nfungicidas <- read_excel(\"dados-diversos.xlsx\", \"fungicida_campo\")"
  },
  {
    "objectID": "R_codes/aula12.html#modelo-anova-com-bloco",
    "href": "R_codes/aula12.html#modelo-anova-com-bloco",
    "title": "DBC",
    "section": "Modelo ANOVA com bloco",
    "text": "Modelo ANOVA com bloco\n\n#sev (resposta)\n#diferença do dic é o rep\naov_fung <- aov(sev ~ trat + rep, data = fungicidas)\nsummary(aov_fung)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \ntrat         7   7135  1019.3 287.661 <2e-16 ***\nrep          1     19    18.6   5.239 0.0316 *  \nResiduals   23     81     3.5                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#se não der significativo, deixa o bloco, pq o delineamento foi em bloco"
  },
  {
    "objectID": "R_codes/aula12.html#checar-premissas",
    "href": "R_codes/aula12.html#checar-premissas",
    "title": "DBC",
    "section": "Checar premissas",
    "text": "Checar premissas\n\n#verificar as premissas\nlibrary(performance)\n#ou\nlibrary(DHARMa)\ncheck_normality(aov_fung)\n\nOK: residuals appear as normally distributed (p = 0.230).\n\ncheck_heteroscedasticity(aov_fung)\n\nOK: Error variance appears to be homoscedastic (p = 0.484).\n\n#plot do DHARMA\nplot(simulateResiduals(aov_fung))\n\n\n\nlibrary(emmeans)\n\n#rodar a média (aov_fung em função de trat)\nmeans_fung <- emmeans(aov_fung, ~ trat)\nlibrary(multcomp)\nlibrary(multcompView)\n\ncld(means_fung)\n\n trat       emmean    SE df lower.CL upper.CL .group\n G            29.2 0.941 23     27.3     31.2  1    \n B            29.5 0.941 23     27.6     31.4  1    \n E            30.1 0.941 23     28.2     32.1  1    \n C            30.4 0.941 23     28.4     32.3  1    \n A            30.4 0.941 23     28.4     32.3  1    \n D            31.5 0.941 23     29.6     33.4  12   \n F            35.5 0.941 23     33.6     37.4   2   \n testemunha   75.8 0.941 23     73.8     77.7    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nplot(means_fung)+\ncoord_flip()+\ntheme_minimal()"
  },
  {
    "objectID": "R_codes/aula12.html#bloco-com-parcela-subdividida",
    "href": "R_codes/aula12.html#bloco-com-parcela-subdividida",
    "title": "DBC",
    "section": "Bloco com parcela subdividida",
    "text": "Bloco com parcela subdividida\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\n#Base R\n#DBC\n#model\n\n#bloco com parcela subdividida precisa de estrutura de erro (bloco, parcela principal, subparcela)(Error)\naov_milho_bloco <- aov(index ~ factor(block) + hybrid*method +\nError(factor(block)/hybrid/method), data = milho)\n\nsummary(aov_milho_bloco)\n\n\nError: factor(block)\n              Df Sum Sq Mean Sq\nfactor(block)  3  592.2   197.4\n\nError: factor(block):hybrid\n          Df Sum Sq Mean Sq F value Pr(>F)  \nhybrid     5  974.2  194.84    3.14 0.0389 *\nResiduals 15  930.9   62.06                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: factor(block):hybrid:method\n              Df Sum Sq Mean Sq F value Pr(>F)  \nmethod         1  79.61   79.61   4.726 0.0433 *\nhybrid:method  5 265.28   53.06   3.150 0.0324 *\nResiduals     18 303.18   16.84                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#usando avo não permitiu checar a normalidade, usar outro modelo (misto)"
  },
  {
    "objectID": "R_codes/aula12.html#modelo-misto",
    "href": "R_codes/aula12.html#modelo-misto",
    "title": "DBC",
    "section": "Modelo misto",
    "text": "Modelo misto\n\n#lme4 - pacote que permite checar as premissas. O modelo misto é mais moderno que o aov\nlibrary(lme4)\n#usando bloco\nmilho$block <- as.factor(milho$block)\n#sqrt para transformar os dados e atender a heterocedasticidade\nmix2 <- lmer(sqrt(index) ~ block + hybrid*method +\n (1|block/hybrid), data = milho)\nlibrary(car)\n#anova no modelo misto não dá o p-valor, só o F. Então, do pacote car, usar anova com A maiusculo \nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nblock          0.0764  3   0.994506   \nhybrid        15.4171  5   0.008721 **\nmethod         3.9239  1   0.047605 * \nhybrid:method 13.3025  5   0.020703 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.422).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.970).\n\n#comparação de médias\n#inverter hybrid e method para fazer outra comparação\nmeans_mix2 <- emmeans(mix2, ~ hybrid|method)\nmeans_mix2\n\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL\n 30F53 HX   5.00 1.17 5356     2.69     7.30\n 30F53 YH   4.95 1.17 5356     2.65     7.25\n 30K64      4.50 1.17 5356     2.20     6.81\n 30S31H     6.10 1.17 5356     3.79     8.40\n 30S31YH    5.63 1.17 5356     3.33     7.93\n BG7049H    4.40 1.17 5356     2.10     6.71\n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL\n 30F53 HX   4.94 1.17 5356     2.64     7.25\n 30F53 YH   5.10 1.17 5356     2.80     7.41\n 30K64      4.61 1.17 5356     2.31     6.91\n 30S31H     5.13 1.17 5356     2.83     7.43\n 30S31YH    5.14 1.17 5356     2.84     7.44\n BG7049H    4.37 1.17 5356     2.07     6.67\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \n\ncld(means_mix2) #na tabela, letras maiúsculas comparam na coluna e minúsculas na linha\n\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    4.40 1.17 5356     2.10     6.71  1    \n 30K64      4.50 1.17 5356     2.20     6.81  1    \n 30F53 YH   4.95 1.17 5356     2.65     7.25  12   \n 30F53 HX   5.00 1.17 5356     2.69     7.30  12   \n 30S31YH    5.63 1.17 5356     3.33     7.93  12   \n 30S31H     6.10 1.17 5356     3.79     8.40   2   \n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    4.37 1.17 5356     2.07     6.67  1    \n 30K64      4.61 1.17 5356     2.31     6.91  1    \n 30F53 HX   4.94 1.17 5356     2.64     7.25  1    \n 30F53 YH   5.10 1.17 5356     2.80     7.41  1    \n 30S31H     5.13 1.17 5356     2.83     7.43  1    \n 30S31YH    5.14 1.17 5356     2.84     7.44  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/aula13.html",
    "href": "R_codes/aula13.html",
    "title": "Simples, Misto e GLM",
    "section": "",
    "text": "Aula 13\nAnálise de regressão estuda a relação entre uma variável dependente (resposta) e outras variáveis independentes (explicativas).Ela permite construir um modelo matemático que represente dois atributos x e y. A análise de regressão indica o efeito de uma mudança da unidade na variável explicativa (x) em relação a variável resposta (y). Ela descreve o efeito, por meio de uma equação, da variável explicativa em relação a variável resposta.\nJá a correlação linear, resume (mensura) o grau de associação entre duas variáveis (x e y). Fornece um número que resume o grau de associação entre a duas variáveis.\nPara fatores com níveis quantitavos se faz análise de regressão e não de média. Para essa aula, será feita análise de regressão (fator quantitativo). O objetivo é ajustar um modelo (função ou equação) teórico que permite estimar qualquer valor (3,2,2.6,6….). Nesse caso, queremos saber se há efeito significativo do inóculo na taxa de emergência, se não tiver efito, é observado uma linha reta, mas se tiver, a reta terá uma inclinação (snoop = coeficiente angular da reta). Se o snoop for zero, o ângulo é zero. O p-valor da regressão é se o snoop (diminuição ou aumento) é significativamente diferetne de zero.\nO primeiro passo é fazer uma análise exploratório de representação com o gráfico geom_point, depois ajusta o modelo ao colocar a tendência (regressão linear) de primeira ordem (há dois parâmetros ou coeficientes).\nUsar modelo misto ou simples, não os dois"
  },
  {
    "objectID": "R_codes/aula13.html#modelo-linear-simples-fator-fixo",
    "href": "R_codes/aula13.html#modelo-linear-simples-fator-fixo",
    "title": "Simples, Misto e GLM",
    "section": "Modelo linear simples (fator fixo)",
    "text": "Modelo linear simples (fator fixo)\n\nexp1 <- estande |> \n  filter(exp == 1)\n# nplants é a resposta\nm1 <- lm(nplants ~ trat, data = exp1)\nsummary(m1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\nexp2 <- estande |> \n  filter(exp == 2)\n\n# nplants é a resposta\nm2 <- lm(nplants ~ trat, data = exp2)\nsummary(m2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nexp3 <- estande |> \n  filter(exp == 3)\n\n# nplants é a resposta\nm3 <- lm(nplants ~ trat, data = exp3)\nsummary(m3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n# Modelo de regressão linear simples: y= B0 + B1*X\n# B0 = beta zero (interceptor): é o valor no qual a linha ajsutada cruza o eixo Y. Interpretação: é o valor médio de resposta quando todas as variáveis explicativas são definidas como zero.No m3, se o trat (número de inóculos) for igual a zero, o valor médio seria 95.7500.\n# B1 = \"trat\" (a cada aumento de uma unidade do trat, espera-se uma diminuição média de -0.7634 (m3) no número de plantas (nplants))\n#x = variável explicativa\n\n#Adjusted R-squared: R², indica quantos porcento da variabilidade de y está sendo explicada por x.\n\n#Multiple R-squared:  0.6085 (m3): é uma medida que indica quão bem o medelo prevê os dados observados.\n\n# p-valor < 2e-16 *** (m3): é a probabilidade que a variável não seja relevante para o modelo. Quanto mais asterísticos presentes ao lado do efeito estimado, maior o nível de confiança com o que podemos afirmar que o efeito não é nulo. Ou seja, se o p-valor for menor que 0.05 a variável é significativa para o modelo, ou seja, as alterações na variável explicativa influenciam nas alterações da variável resposta. Se o p-valor for >0.05, sugere que as mudanças na variável explicativa não estão associadas as mudanças na variável resposta.\n\n#Residuals (m3): informações referente aos resíduos do modelo. É a diferença do valor previsto e o valor real.\n\n\n\nlibrary(report)\nreport(m1)\n\nWe fitted a linear model (estimated using OLS) to predict nplants with trat\n(formula: nplants ~ trat). The model explains a statistically not significant\nand weak proportion of variance (R2 = 0.07, F(1, 22) = 1.69, p = 0.207, adj. R2\n= 0.03). The model's intercept, corresponding to trat = 0, is at 52.50 (95% CI\n[43.78, 61.22], t(22) = 12.49, p < .001). Within this model:\n\n  - The effect of trat is statistically non-significant and negative (beta =\n-0.24, 95% CI [-0.63, 0.14], t(22) = -1.30, p = 0.207; Std. beta = -0.27, 95%\nCI [-0.69, 0.16])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\ng1 <- exp1 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_abline(intercept = 52.5, slope = -0.24)+\n    ylim(0, max(estande$nplants))+\n  #geom_smooth(method = \"lm\", se = F)+\n  annotate(geom =  \"text\", x = 24,\n           y = 70, label = \"y = 52.5 -0.24x\")\n\ng2 <- exp1 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0, max(estande$nplants))+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom =  \"text\", x = 24,\n           y = 70, label = \"y = 60 -0.7x\")\n\ng3 <- exp1 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0, max(estande$nplants))+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom =  \"text\", x = 24,\n           y = 70, label = \"y = 95 -0.7x\")\n\nlibrary(patchwork)\ng1 | g2 | g3"
  },
  {
    "objectID": "R_codes/aula13.html#modelo-misto",
    "href": "R_codes/aula13.html#modelo-misto",
    "title": "Simples, Misto e GLM",
    "section": "Modelo misto",
    "text": "Modelo misto\nTem fator fixo e aleatório. Junta os 3 experimentos em um modelo só e compara se houve significancia nos 3 ou não.\n\nlibrary(lme4)\nmix <- lmer(nplants ~ trat + (trat | exp),\n        data = estande)\nsummary(mix)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nlibrary(car)\nAnova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: nplants\n      Chisq Df Pr(>Chisq)    \ntrat 11.985  1  0.0005362 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nestande |> \n  ggplot(aes(trat, nplants, group = exp))+\n  geom_point()+\n  ylim(0, max(estande$nplants))+\n  #linha de tendência é uma linha suavisada para ver o padrão\n  geom_smooth(se = F, method = \"lm\")\n\n\n\n\n\nModelo GLM\nModelo linear é um caso especial do GLM\n\nlm1 <- lm(nplants ~ trat, data = exp3)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n# glm \"gaussian\" é o mesmo lm\n# \"gaussian\" é para dados contínuos, pode ser menor que zero\n# poisson\n\n# Ajustar o modelo aos dados\nglm1 <- glm(nplants ~ trat, family = \"gaussian\",\n           data = exp3)\n\nglm2 <- glm(nplants ~ trat, family = \"poisson\" (link = \"log\"),\n           data = exp3)\n#Informação critério de arcaique - quanto menor o AIC, melhor o modelo\nAIC(glm1)\n\n[1] 185.0449\n\nAIC(glm2)\n\n[1] 183.9324\n\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\nsummary(glm2)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "R_codes/aula14.html",
    "href": "R_codes/aula14.html",
    "title": "Linear de segunda ordem",
    "section": "",
    "text": "Aula 14\nCom mais um parâmetro, quadrática\nNesse exemplo tem-se uma variável independente, que é um nível de um fator do experimento. Como é quantitativo, fazer regressão linear. Então, deve-se observar se é linear simples ou quadrática (nesse caso). Logo, usar o “lm”, verificar o ajuste, verificar os coeficientes, pegar a equação que vai predizer o valor de y para cada valor de x ou x², dependendo do modelo usado, que vai reportar os coeficientes de variação, o R²."
  },
  {
    "objectID": "R_codes/aula14.html#ajustar-modelo-de-segunda-ordem",
    "href": "R_codes/aula14.html#ajustar-modelo-de-segunda-ordem",
    "title": "Linear de segunda ordem",
    "section": "Ajustar modelo de segunda ordem",
    "text": "Ajustar modelo de segunda ordem\nVariável independente\n\n# \n\nlibrary(readxl)\nlibrary(tidyverse)\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\n\nestande |> \n  ggplot(aes(trat, nplants, group = exp))+\n  geom_point()+\n  facet_wrap(~exp)+\n  ylim(0, max(estande$nplants))+\n  geom_smooth(se = F)"
  },
  {
    "objectID": "R_codes/aula14.html#ajustar-modelo-linear-e-quadrático-no-ggplot",
    "href": "R_codes/aula14.html#ajustar-modelo-linear-e-quadrático-no-ggplot",
    "title": "Linear de segunda ordem",
    "section": "Ajustar modelo linear e quadrático no ggplot",
    "text": "Ajustar modelo linear e quadrático no ggplot\n\nestande2 <- estande |> \n  filter(exp ==2) |> \n  group_by(trat) |>\n  summarise(mean_nplants = mean(nplants))\n\nestande2 |> \n  ggplot(aes(trat, mean_nplants))+\n  geom_point()+\n  #geom_line()+\n  geom_smooth(se = F, formula = y ~ poly(x, 2), method = \"lm\", color = \"black\")+\n  theme_minimal()+\n  annotate(geom = \"text\",\n           x = 25, y = 70,\n           label = \"y = 66.3 - 1.777x + 0.0222x²\n           R² = 0.88\")\n\n\n\n# R² = coeficiente de determinação, 49 minutos\n\n\nestande2 <- estande2 |> \n  mutate(trat2 = trat^2)\n\nm1 <- lm(mean_nplants ~ trat, data = estande2)\nsummary(m1)\n\n\nCall:\nlm(formula = mean_nplants ~ trat, data = estande2)\n\nResiduals:\n     1      2      3      4      5      6 \n12.764 -2.134 -6.782 -3.327 -4.669  4.147 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     4.5505  13.402 0.000179 ***\ntrat         -0.7007     0.2012  -3.483 0.025294 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.117 on 4 degrees of freedom\nMultiple R-squared:  0.752, Adjusted R-squared:   0.69 \nF-statistic: 12.13 on 1 and 4 DF,  p-value: 0.02529\n\n# Adjusted R-squared:   0.69 = 69% de plantas é explicado pelo tratamento de acordo com o modelo linear.\n# histograma dos resíduos\nhist(m1$residuals)\n\n\n\nm2 <- lm(mean_nplants ~ trat + trat2, data = estande2)\nsummary(m2)\n\n\nCall:\nlm(formula = mean_nplants ~ trat + trat2, data = estande2)\n\nResiduals:\n      1       2       3       4       5       6 \n 7.4484 -4.4200 -6.4386  1.0739  3.0474 -0.7111 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 66.30156    4.70800  14.083 0.000776 ***\ntrat        -1.77720    0.62263  -2.854 0.064878 .  \ntrat2        0.02223    0.01242   1.790 0.171344    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.517 on 3 degrees of freedom\nMultiple R-squared:  0.8801,    Adjusted R-squared:  0.8001 \nF-statistic: 11.01 on 2 and 3 DF,  p-value: 0.04152\n\nAIC(m1, m2)\n\n   df      AIC\nm1  3 45.72200\nm2  4 43.36151"
  },
  {
    "objectID": "R_codes/aula14.html#relacionar-duas-respostas",
    "href": "R_codes/aula14.html#relacionar-duas-respostas",
    "title": "Linear de segunda ordem",
    "section": "Relacionar duas respostas",
    "text": "Relacionar duas respostas\nDuas variáveis resposta do tipo númerica quantitativa. Para saber se há associação entre duas variáveis dependentes.\nPrimeiro, fazer análise para testar a associação. A análise de correlação dá o coeficiente de correlação de Pearson (R), que é a raiz do R², que será sempre maior que o R².\n\nmofo <- read_excel(\"dados-diversos.xlsx\", \"mofo\")\n\nmofo |> \n  ggplot(aes(inc, yld))+\n  geom_point()+\n  facet_wrap(~study)+\n  geom_smooth(se = F, method = \"lm\")"
  },
  {
    "objectID": "R_codes/aula14.html#correlação-linear",
    "href": "R_codes/aula14.html#correlação-linear",
    "title": "Linear de segunda ordem",
    "section": "Correlação linear",
    "text": "Correlação linear\n\nmofo1 <- mofo |> \n  filter(study == 3)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n\n# Correlação linear resume (mensura) o grau de associação entre duas variáveis (x e y). Fornece um número que resume o grau de associação entre a duas variáveis. A análise de regressão indica o efeito de uma mudança da unidade na variável explicativa (x) em relação a variável resposta (y). Ela descreve o efeito, por meio de uma equação, da variável explicativa em relação a variável resposta.\n# teste de correlação de pearson, quando tem normalidade. Testar a associação. Quanto maior o cor, maior a associação. Quanto mais disperso os pontos, menor a associação.\ncor.test(mofo1$inc, mofo1$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -10.9, df = 11, p-value = 3.105e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9872663 -0.8579544\nsample estimates:\n      cor \n-0.956692 \n\n#função cor\npcor <- cor(mofo1 |> select(3:5))\nlibrary(corrplot)\ncorrplot (pcor, method = \"number\", type = \"lower\")"
  },
  {
    "objectID": "R_codes/aula14.html#spearman-não-paramétrica",
    "href": "R_codes/aula14.html#spearman-não-paramétrica",
    "title": "Linear de segunda ordem",
    "section": "Spearman (não paramétrica)",
    "text": "Spearman (não paramétrica)\n\nmofo1 <- mofo |> \n  filter(study == 3)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n\n#teste de normalidade\nshapiro.test(mofo$inc)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mofo$inc\nW = 0.94315, p-value = 0.01507\n\n# usar spearman (não paramétrica, quando não assume normalidade) quando falta de normalidade. Usar sperarman como padrão \ncor.test(mofo1$inc, mofo1$yld, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  mofo1$inc and mofo1$yld\nS = 715.97, p-value = 7.166e-08\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.9669458 \n\n#função cor\npcor <- cor(mofo1 |> select(3:5), method = \"spearman\")\nlibrary(corrplot)\ncorrplot (pcor, method = \"number\", type = \"lower\")"
  },
  {
    "objectID": "R_codes/aula14.html#kendall-não-paramétrica",
    "href": "R_codes/aula14.html#kendall-não-paramétrica",
    "title": "Linear de segunda ordem",
    "section": "kendall (não paramétrica)",
    "text": "kendall (não paramétrica)\n\nmofo1 <- mofo |> \n  filter(study == 3)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n\n#teste de normalidade\nshapiro.test(mofo$inc)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mofo$inc\nW = 0.94315, p-value = 0.01507\n\n# usar kendall (não paramétrica, quando não assume normalidade) para dados (variável) ordinais\ncor.test(mofo1$inc, mofo1$yld, method = \"kendall\")\n\n\n    Kendall's rank correlation tau\n\ndata:  mofo1$inc and mofo1$yld\nz = -4.1641, p-value = 3.125e-05\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n       tau \n-0.8831914 \n\n#função cor\npcor <- cor(mofo1 |> select(3:5), method = \"kendall\")\nlibrary(corrplot)\ncorrplot (pcor, method = \"number\", type = \"lower\")"
  },
  {
    "objectID": "R_codes/aula15.html",
    "href": "R_codes/aula15.html",
    "title": "Chi-squared/Fisher’s Test",
    "section": "",
    "text": "Aula 15\nTeste para dados de levantamento e variável categorica nominal ano, resto cultural…"
  },
  {
    "objectID": "R_codes/aula15.html#curva-de-progresso-da-severidade",
    "href": "R_codes/aula15.html#curva-de-progresso-da-severidade",
    "title": "Chi-squared/Fisher’s Test",
    "section": "Curva de progresso da severidade",
    "text": "Curva de progresso da severidade\nPlanilha dados-diversos, aba curve: dado temporal\n\ncurve <- read_excel(\"dados-diversos.xlsx\", \"curve\")\n\ncurve |> \n  group_by(Irrigation, day) |> # manter irrigation e day e desconsiderar rep\n  summarise(mean_severity = mean(severity), \n            sd_severity = sd(severity))|> \n  ggplot(aes(day, mean_severity, color = Irrigation))+\n  geom_point()+\n  geom_errorbar(aes(ymin = mean_severity - sd_severity, ymax = mean_severity + sd_severity), width = 0.1)+\n  geom_line()\n\n\n\n# Calcular área abaixo da curva do progresseo da doença\n\nlibrary(epifitter)\n\ncurve3 <- curve |> \n  group_by(Irrigation, rep) |> \n  summarise(audpc = AUDPC(day, severity, \n                          y_proportion = F)) |> \n  # Aplicar T-test para dois grupos\n  # Primeiro passar para o formato largo\n  pivot_wider(1, names_from = Irrigation, values_from = audpc)\n\nt.test(curve3$Drip, curve3$Furrow)\n\n\n    Welch Two Sample t-test\n\ndata:  curve3$Drip and curve3$Furrow\nt = -1.3773, df = 3.079, p-value = 0.26\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.3421436  0.5231436\nsample estimates:\nmean of x mean of y \n 13.38983  13.79933"
  },
  {
    "objectID": "R_codes/aula15.html#experimetno-fatorial",
    "href": "R_codes/aula15.html#experimetno-fatorial",
    "title": "Chi-squared/Fisher’s Test",
    "section": "Experimetno fatorial",
    "text": "Experimetno fatorial\n\nlibrary(gsheet)\ntw <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1t5xftb0xSRPNFhM7h_MiPNtwt2UFUcm9/edit?rtpof=true\")\n\ntw |> \n  group_by(cult, silicio, hai) |> \n   summarise(mean_lesion = mean(lesion_size), sd_lesion = sd(lesion_size)) |> \n  ggplot(aes(hai, mean_lesion, color = silicio))+\n  geom_point()+\n  geom_errorbar(aes(ymin = mean_lesion - sd_lesion, \n                    ymax = mean_lesion + sd_lesion), \n                width = 0.1)+\n  geom_line()+\n  facet_wrap(~cult)+\n  labs(x = \"Hours after inoculation\", y = \"Lesion size (mm)\")\n\n\n\n# Calcular área abaixo da curva do tamanho da lesão\n\nlibrary(epifitter)\n\ntw2 <- tw |> \n  group_by(exp, cult, silicio, rep) |> \n  summarise(audpc = AUDPC(lesion_size, hai))\n\ntw2|> \n  ggplot(aes(cult, audpc, color = silicio))+\n  geom_boxplot()+\n  facet_wrap(~exp)"
  },
  {
    "objectID": "R_codes/aula15.html#anova-aov-para-área-abaixo-da-curva",
    "href": "R_codes/aula15.html#anova-aov-para-área-abaixo-da-curva",
    "title": "Chi-squared/Fisher’s Test",
    "section": "ANOVA aov() para área abaixo da curva",
    "text": "ANOVA aov() para área abaixo da curva\n\n# qualitativo, ANOVA para a área abaixo da curva\n# Experimetno fatorial. Primeiro, testar o experimento completo, se não for significativo, reduzir o modelo. \naov1 <- aov(audpc ~exp*cult*silicio, data = tw2)\nsummary(aov1) # não deu significativo\n\n                 Df  Sum Sq Mean Sq F value   Pr(>F)    \nexp               1   54544   54544   0.533 0.470257    \ncult              1  751290  751290   7.335 0.010281 *  \nsilicio           1 9051552 9051552  88.377 3.15e-11 ***\nexp:cult          1   36717   36717   0.359 0.553089    \nexp:silicio       1      49      49   0.000 0.982615    \ncult:silicio      1 1412562 1412562  13.792 0.000689 ***\nexp:cult:silicio  1  143643  143643   1.403 0.244065    \nResiduals        36 3687093  102419                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\naov1 <- aov(sqrt(audpc) ~cult*silicio, data = tw2)\nsummary(aov1) # modelo reduzido, foi significativo\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \ncult          1  294.0   294.0   13.51 0.000712 ***\nsilicio       1 2363.9  2363.9  108.65 7.81e-13 ***\ncult:silicio  1  526.5   526.5   24.20 1.62e-05 ***\nResiduals    39  848.6    21.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 observation deleted due to missingness\n\nlibrary(performance)\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.146).\n\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.638).\n\nlibrary(emmeans)\nm1 <- emmeans(aov1, ~ cult | silicio, type = \"response\")\nm1\n\nsilicio = Si-:\n cult      response    SE df lower.CL upper.CL\n Horizonte     1440 106.8 39     1233     1664\n Quartzo       1537 110.3 39     1322     1768\n\nsilicio = Si+:\n cult      response    SE df lower.CL upper.CL\n Horizonte      897  84.2 39      735     1075\n Quartzo        296  50.7 39      202      407\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale"
  },
  {
    "objectID": "R_codes/aula16.html",
    "href": "R_codes/aula16.html",
    "title": "Mapas",
    "section": "",
    "text": "Aula 16"
  },
  {
    "objectID": "R_codes/aula16.html#carregar-pacotes",
    "href": "R_codes/aula16.html#carregar-pacotes",
    "title": "Mapas",
    "section": "Carregar pacotes",
    "text": "Carregar pacotes\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\n\nlibrary(remotes)\nremotes::install_github(\"emdelponte/r4pde\")\nlibrary(r4pde)\n\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)"
  },
  {
    "objectID": "R_codes/aula16.html#instalar-pacote-do-github",
    "href": "R_codes/aula16.html#instalar-pacote-do-github",
    "title": "Mapas",
    "section": "Instalar pacote do github:",
    "text": "Instalar pacote do github:\n\nremotes::install_github(\"ropensci/rnaturalearthhires\")"
  },
  {
    "objectID": "R_codes/aula16.html#mapa-do-brasil",
    "href": "R_codes/aula16.html#mapa-do-brasil",
    "title": "Mapas",
    "section": "Mapa do Brasil",
    "text": "Mapa do Brasil\nPara plotar o mapa do país, usa-se a função “ne_countries”\n\nsbr <- RustSoybean\n\nBRA <- ne_countries(country = \"Brazil\", \n                    returnclass = \"sf\")\nggplot(BRA) +\ngeom_sf(fill = \"white\")"
  },
  {
    "objectID": "R_codes/aula16.html#plotar-os-estados",
    "href": "R_codes/aula16.html#plotar-os-estados",
    "title": "Mapas",
    "section": "Plotar os estados",
    "text": "Plotar os estados\n\nBRA <- ne_states(country = \"Brazil\", \n                    returnclass = \"sf\")\nggplot(BRA) +\ngeom_sf(color = \"white\",\n          fill = \"darkgreen\") +\n  theme_void()"
  },
  {
    "objectID": "R_codes/aula16.html#selecionar-um-estado",
    "href": "R_codes/aula16.html#selecionar-um-estado",
    "title": "Mapas",
    "section": "Selecionar um estado",
    "text": "Selecionar um estado\n\nBRA <- ne_states(country = \"Brazil\", \n                    returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\nggplot(BRA) +\ngeom_sf(color = \"black\",\n          fill = \"white\") +\n  geom_sf(data = MG, color = \"black\",\n            fill = \"green\")"
  },
  {
    "objectID": "R_codes/aula16.html#pontos-especificos-dos-dados-no-mapa-latitude-e-longitude",
    "href": "R_codes/aula16.html#pontos-especificos-dos-dados-no-mapa-latitude-e-longitude",
    "title": "Mapas",
    "section": "Pontos especificos dos dados no mapa (latitude e longitude)",
    "text": "Pontos especificos dos dados no mapa (latitude e longitude)\nPara plotar os pontos, precisa-se das coordenadas de onde foram coletados os pontos. Ex.: pontos de coleta - precisa-se coletar as coordenadas para plotar em um mapa (no caso de ser só o municipio, pode pegar na internet as coordenadas).\n\nBRA <- ne_states(country = \"Brazil\", \n                    returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\nggplot(BRA) +\ngeom_sf(color = \"black\",\n          fill = \"white\") +\n  geom_point(data = sbr, aes(longitude, latitude), alpha = 0.5)"
  },
  {
    "objectID": "R_codes/aula16.html#mapas-interativos",
    "href": "R_codes/aula16.html#mapas-interativos",
    "title": "Mapas",
    "section": "Mapas interativos",
    "text": "Mapas interativos\n\nsbr <- RustSoybean\n\nBRA <- ne_states(country = \"Brazil\", \n                    returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\n\nm <- ggplot(BRA) +\ngeom_sf(color = \"black\",\n          fill = \"white\") +\n  geom_point(data = sbr, aes(longitude, latitude), alpha = 0.5)\n\nlibrary(plotly)\n  ggplotly(m)# passe o cursor por cima dos pontos no mapa\n\n\n\n\n#O pacote leaflet cria um mapa interativo como Google Maps utilizando coordenadas geográficas\nlat = -20.7474\nlong = -42.883\ndat <- data.frame(lat, long)\nlibrary(leaflet)\n\ndat |> \n  leaflet() |> \n  addProviderTiles(providers$Esri.WorldImagery) |> \n  addMarkers() #tipo de ponto no mapa\n\n\n\n\n  #addTiles() |>\n  #addCircleMarkers() #ponto tipo círculo no mapa"
  },
  {
    "objectID": "R_codes/aula16.html#separar-a-data-em-dia-mês-e-ano",
    "href": "R_codes/aula16.html#separar-a-data-em-dia-mês-e-ano",
    "title": "Mapas",
    "section": "Separar a data em dia, mês e ano",
    "text": "Separar a data em dia, mês e ano\n\nsbr2 <- sbr |>\n  separate(planting, into = \n             c(\"year\", \"month\", \"day\"), sep = \"-\", remove = FALSE)\n\nBRA <- ne_states(country = \"Brazil\", \n                    returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\nggplot(BRA) +\ngeom_sf(color = \"black\",\n          fill = \"white\") +\n  geom_point(data = sbr2,\n             aes(longitude, latitude, color = year), alpha = 0.5)+\n  facet_wrap(~year)+\n  theme_void()"
  },
  {
    "objectID": "R_codes/aula16.html#inserir-rosa-dos-ventos-e-escala",
    "href": "R_codes/aula16.html#inserir-rosa-dos-ventos-e-escala",
    "title": "Mapas",
    "section": "Inserir rosa dos ventos e escala",
    "text": "Inserir rosa dos ventos e escala\n\nlibrary(ggspatial)\nggplot(BRA) +\n  annotation_north_arrow(location = \"bl\")+\n  annotation_scale(location = \"br\")+\n  geom_sf(color = \"black\",\n          fill = \"white\") +\n  geom_point(data = sbr2,\n             aes(longitude, latitude, color = year, size = severity), alpha = 0.5)+\n  labs(color = \"Planting Year\")+\n  theme_minimal()+\n  theme(legend.position = \"right\")"
  },
  {
    "objectID": "R_codes/aula16.html#malha-de-municípios",
    "href": "R_codes/aula16.html#malha-de-municípios",
    "title": "Mapas",
    "section": "Malha de municípios",
    "text": "Malha de municípios\nBaixar arquivo “shape” dos municípios em um site do IBJE Usar pacote rgdal\nPara todos os municípios, chunk comentado\n\n#library(rgdal)\n#library(sf)\n#shapefile <- st_read(\"Aula16_BR_Municipios_2022/BR_Municipios_2022.shp\")\n#ggplot(BRA) +\n  #geom_sf(data = shapefile)\n\nPara MG\n\nshapefile <- sf::st_read(\"MG_Municipios_2022/MG_Municipios_2022.shp\") \n\nReading layer `MG_Municipios_2022' from data source \n  `C:\\Users\\rbarb\\OneDrive\\Documentos\\GitHub\\FIP606\\R_codes\\MG_Municipios_2022\\MG_Municipios_2022.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 853 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -51.04608 ymin: -22.92276 xmax: -39.85683 ymax: -14.23318\nGeodetic CRS:  SIRGAS 2000\n\nggplot(MG) +\n  geom_sf(data = shapefile)"
  },
  {
    "objectID": "R_codes/aula17.html",
    "href": "R_codes/aula17.html",
    "title": "Não Linear",
    "section": "",
    "text": "Aula 17"
  },
  {
    "objectID": "R_codes/aula17.html#para-estimar-ec50",
    "href": "R_codes/aula17.html#para-estimar-ec50",
    "title": "Não Linear",
    "section": "Para estimar EC50",
    "text": "Para estimar EC50\nEC50: valor da dose que reduz 50% do crescimento micelial comparado com a dose zero\n\nlibrary(gsheet)\nlibrary(tidyverse)\n\ndat <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/15pCj0zljvd-TGECe67OMt6sa21xO8BqUgv4d-kU8qi8/edit#gid=0\")\n\n# Fazer sumarização\n\noptions(scipen=999)\ndat2 <- dat |> \n  select(-Isolate, -Population) |> \n# juntar em um valor só\n  group_by(Code, Year, Dose) |> # group_by trabalha junto com summarise\n    summarise(GC_mean = mean(GC))\n\nFGT152 <- dat2 |> \n  filter(Code == \"FGT152\")\n\nFGT152 |> \n  ggplot(aes(factor(Dose), GC_mean))+\n  geom_point()+\n  geom_line()\n\n\n\ndat2 |> \n  ggplot(aes(factor(Dose), GC_mean))+\n  geom_point()+\n  geom_line()+\n  facet_wrap(~Code)"
  },
  {
    "objectID": "R_codes/aula17.html#ec50-com-pacote-drm",
    "href": "R_codes/aula17.html#ec50-com-pacote-drm",
    "title": "Não Linear",
    "section": "EC50 com pacote DRM",
    "text": "EC50 com pacote DRM\n\nlibrary(drc)\n\n# modelo LL.3 (modelo de três parâmetros e intercepta o eixo X)\ndrc1 <- drm(GC_mean ~ Dose, data = FGT152,\n    fct = LL.3())\nAIC(drc1) # qual o modelo melhor, quanto menor melhor\n\n[1] 33.60846\n\nsummary(drc1)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value     p-value    \nb:(Intercept)  0.401905   0.053427  7.5225    0.001672 ** \nd:(Intercept) 47.540342   1.459890 32.5643 0.000005302 ***\ne:(Intercept)  7.220130   2.340119  3.0854    0.036739 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.993805 (4 degrees of freedom)\n\nplot(drc1)\n\n\n\nED(drc1, 50)\n\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50   7.2201     2.3401\n\n# modelo W1.3\ndrc2 <- drm(GC_mean ~ Dose, data = FGT152,\n    fct = W1.3())\nAIC(drc2) # qual o modelo melhor\n\n[1] 37.75192\n\nsummary(drc2)\n\n\nModel fitted: Weibull (type 1) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n              Estimate Std. Error t-value    p-value    \nb:(Intercept)  0.28354    0.04760  5.9567   0.003987 ** \nd:(Intercept) 48.38112    2.09996 23.0390 0.00002103 ***\ne:(Intercept) 30.12379   12.58003  2.3946   0.074796 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.680509 (4 degrees of freedom)\n\nplot(drc2)\n\n\n\nED(drc2, 50)\n\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50   8.2704     3.6719\n\n\n\nlibrary(ec50estimator)\n\ndf_ec50 <- estimate_EC50(GC_mean ~ Dose, \n                         data = dat2,\n                         isolate_col = \"Code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\n\ndf_ec50 |> \n  ggplot(aes(Estimate))+\n  geom_histogram()\n\n\n\ndf_ec50 |>\n  ggplot(aes(Estimate, reorder(ID, Estimate)))+\n  geom_point()+\n  geom_errorbar(aes(xmin = Lower,\n                    xmax = Upper), width = 0.1)+\n  xlim(0,30)"
  },
  {
    "objectID": "R_codes/aula18.html",
    "href": "R_codes/aula18.html",
    "title": "Transformação Box Cox",
    "section": "",
    "text": "Aula 18\nObservação: dados da aula 10"
  },
  {
    "objectID": "R_codes/aula18.html#transformação-de-dados",
    "href": "R_codes/aula18.html#transformação-de-dados",
    "title": "Transformação Box Cox",
    "section": "Transformação de dados",
    "text": "Transformação de dados\n\nO modelo de Análise de Variância pressupõe que exista homocedasticidade, ou seja, que os tratamentos apresentem a mesma variabilidade;\nAlgumas vezes este pressuposto pode não ser atendido e assim, para corrigir este problema existe uma saída por vezes bastante simples que é a transformação de dados;\nEsta técnica consiste na utilização de um artifício matemático para tornar o modelo de ANOVA válido."
  },
  {
    "objectID": "R_codes/aula18.html#transformação-box-cox",
    "href": "R_codes/aula18.html#transformação-box-cox",
    "title": "Transformação Box Cox",
    "section": "Transformação Box-Cox",
    "text": "Transformação Box-Cox\nOs estatísticos George Box e David Cox desenvolveram um procedimento para identificar um expoente apropriado (Lambda = 1) a ser usado para transformar dados em uma “forma normal”. Quando o valor de Lambda é 1, nenhuma transformação é necessária, produz resultados idênticos aos originais. O valor Lambda indica a potência à qual todos os dados devem ser elevados. Para isso, a transformação de potência Box-Cox busca de Lambda = -5 a Lamba = +5 até encontrar o melhor valor. A tabela abaixo mostra algumas transformações Box-Cox comuns, onde Y’ é a transformação dos dados originais Y. Observe que para Lambda = 0, a transformação NÃO é Y 0 (porque seria 1 para cada valor), mas sim o logaritmo de Y.\n\n\n\n1\nY’\n\n\n-2\nY-2 = 1/Y2\n\n\n-1\nY-1 = 1/Y1\n\n\n-0.5\nY-0.5 = 1/(Sqrt(Y))\n\n\n0\nlog(Y)\n\n\n0.5\nY0.5 = Sqrt(Y)\n\n\n1\nY1 = Y\n\n\n2\nY2\n\n\n\nA função boxcox foi implementada no pacote MASS. O lambda (λ) é utilizado para transformar a variável resposta pela fórmula “variável resposta ^ lambda - 1”."
  },
  {
    "objectID": "R_codes/aula18.html#transformando-dados",
    "href": "R_codes/aula18.html#transformando-dados",
    "title": "Transformação Box Cox",
    "section": "Transformando dados",
    "text": "Transformando dados\n\nlibrary(readxl)\nlibrary(tidyverse)\nmicelial <- read_excel(\"dados-diversos.xlsx\", \"fungicida_vaso\")\nmicelial <- micelial |> \n  mutate(inc = inf_seeds/n_seeds*100,\n         rank_inc = rank(inc))\n\n# rank transforma dados quando tem-se dois fatores. rank transforma a variável resposta para dois fatores\nrank_anova <- aov(rank_inc ~ treat*dose, data = micelial)\nsummary(rank_anova)\n\n            Df Sum Sq Mean Sq F value  Pr(>F)   \ntreat        1 220.00  220.00  14.204 0.00168 **\ndose         1 105.34  105.34   6.801 0.01904 * \ntreat:dose   1  80.34   80.34   5.187 0.03684 * \nResiduals   16 247.82   15.49                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nmeans_rank <- emmeans(rank_anova, ~ treat | dose)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(means_rank)\n\ndose = 0.5:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole   6.90 1.76 16     3.17     10.6  1    \n Ionic liquid  18.00 1.76 16    14.27     21.7   2   \n\ndose = 2.0:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole   6.75 1.97 16     2.58     10.9  1    \n Ionic liquid   9.75 1.61 16     6.34     13.2  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n# usar boxcox\nlibrary(MASS)\n\n# criando o objeto insects\ninsects <- tibble::as_tibble(InsectSprays)|> \n  dplyr::select(spray, count)\ninsects\n\n# A tibble: 72 × 2\n   spray count\n   <fct> <dbl>\n 1 A        10\n 2 A         7\n 3 A        20\n 4 A        14\n 5 A        14\n 6 A        12\n 7 A        10\n 8 A        23\n 9 A        17\n10 A        20\n# ℹ 62 more rows\n\nb <- boxcox(lm(insects$count+0.1 ~ 1)) # o valor 0.1 é pq tinha zero nos dados; insects$count é a variável resposta \n\n\n\n# Encontra o lambda\nlambda <- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n# Após achar o lambda, a variável resposta é transformada com a fórmula abaixo\n\ninsects$count2 <- (insects$count ^ lambda - 1) / lambda # insects$count2 cria count2 automaticamente, o lambda transformado\ninsects$count2 # variável resposta transformada\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\nhist(insects$count) # muito assimétrico\n\n\n\nhist(insects$count2) # mais simétrico\n\n\n\ninsects$count2\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\n\nO lambda tranformado é usado na ANOVA"
  },
  {
    "objectID": "R_codes/aula19.html",
    "href": "R_codes/aula19.html",
    "title": "Teste de Scott-Knott",
    "section": "",
    "text": "Aula 19\nO teste de Tukey faz comparação múltipla das médias, ele é o teste comum de médias mais utilizado. O Tukey apresenta uma ambiguidade, quando um tratamento recebe duas letras de grupos diferentes. Por exemplo, o resultado do teste de Tukey abaixo mostra que o tratamento E pode ser do grupo b ou c."
  },
  {
    "objectID": "R_codes/aula19.html#teste-de-tukey",
    "href": "R_codes/aula19.html#teste-de-tukey",
    "title": "Teste de Scott-Knott",
    "section": "Teste de Tukey",
    "text": "Teste de Tukey\nAssume-se que o delideamento do experimento “insects” é DIC\n\ninsects <- InsectSprays\nlibrary(ExpDes.pt)\n\ninsects$count2 <- sqrt(insects$count) # sqrt é para transformar dados de contagem; insects$count2\" é do R básico, poderia usar a função \"mutate\".\n\n# usar o pacote para fazer a ANOVA\ndic(insects$spray,\n    insects$count2,\n    mcomp = \"tukey\")\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ      QM     Fc      Pr>Fc\nTratamento  5  88.438 17.6876 44.799 6.3345e-20\nResiduo    66  26.058  0.3948                  \nTotal      71 114.496                          \n------------------------------------------------------------------------\nCV = 22.34 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.6813773 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.5855673 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    F   4.018617 \na    B   3.876631 \na    A   3.760678 \n b   D   2.164354 \n bc      E   1.809461 \n  c      C   1.244857 \n------------------------------------------------------------------------\n\n\nA função do pacote “ExpDes.pt” permite fazer o teste de Scott-Knott para um fator, agrupando os tratamentos de acordo com as médias. A função “dic” do pacote “ExpDes.pt” faz a ANOVA e o agrupamento do Scott-Knott (“sk”), cada tratamento recebe apenas uma letra. O Scott-Knott é utilizado para 15 ou mais de 20 tratamentos. É recomendável fazer o agrupamento dos tratamentos do que analisá-los separadamente. O teste de Scott-Knott é um algorítimo que agrupa os tratamentos de acordo com as médias. Cada tratamento fica em um grupo.\nAs premissas devem ser atendidas no Scott-Knott, deve-se trabalhar com transformação de dados."
  },
  {
    "objectID": "R_codes/aula19.html#scott-knott-1-fator",
    "href": "R_codes/aula19.html#scott-knott-1-fator",
    "title": "Teste de Scott-Knott",
    "section": "Scott-Knott 1 Fator",
    "text": "Scott-Knott 1 Fator\nPesqueisar no help as funções do pacote.\n\ninsects <- InsectSprays\nlibrary(ExpDes.pt)\n\ninsects$count2 <- sqrt(insects$count)\n\ndic(insects$spray,\n    insects$count2,\n    mcomp = \"sk\")\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ      QM     Fc      Pr>Fc\nTratamento  5  88.438 17.6876 44.799 6.3345e-20\nResiduo    66  26.058  0.3948                  \nTotal      71 114.496                          \n------------------------------------------------------------------------\nCV = 22.34 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.6813773 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.5855673 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Scott-Knott\n------------------------------------------------------------------------\n  Grupos Tratamentos   Medias\n1      a           F 4.018617\n2      a           B 3.876631\n3      a           A 3.760678\n4      b           D 2.164354\n5      b           E 1.809461\n6      c           C 1.244857\n------------------------------------------------------------------------\n\n\nObserve que no resultado acima não há tratamento no mesmo grupo. Então, quando você tem um experimento com um número de tratamentos muito grande e quer fazer agrupamento, para verificar quais os tratamentos são iguáis, mas sem abiguidade, use o Scott-Knott."
  },
  {
    "objectID": "R_codes/aula19.html#scott-knott-fatorial",
    "href": "R_codes/aula19.html#scott-knott-fatorial",
    "title": "Teste de Scott-Knott",
    "section": "Scott-Knott Fatorial",
    "text": "Scott-Knott Fatorial\nPara fazer o Scott-Knott fatorial, precisa fazer o teste para cada nível de cada fator.\nDBC\n\ndata(ex5)\nattach(ex5)\nfat2.dbc(trat, genero, bloco, sabor, quali=c(TRUE,TRUE),\nmcomp=\"sk\", fac.names=c(\"Amostras\",\"Genero\"), sigT = 0.05,\nsigF = 0.05, unfold=NULL)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  Amostras \nFATOR 2:  Genero \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                 GL     SQ QM      Fc   Pr>Fc\nBloco            19  97.82  4 1.55116 0.07832\nAmostras          3  19.37  5 1.94522 0.12537\nGenero            1   7.66  6 2.30677 0.13118\nAmostras*Genero   3   3.92  2 0.39356 0.75783\nResiduo         133 441.43  3                \nTotal           159 570.19  1                \n------------------------------------------------------------------------\nCV = 27.58 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.005428379 \nATENCAO: a 5% de significancia, os residuos nao podem ser considerados normais!\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nAmostras\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1    10g  6.850\n2    15g  6.975\n3    15t  6.075\n4    20t  6.525\n------------------------------------------------------------------------\nGenero\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      F 6.8250\n2      M 6.3875\n------------------------------------------------------------------------"
  },
  {
    "objectID": "R_codes/aula19.html#observação",
    "href": "R_codes/aula19.html#observação",
    "title": "Teste de Scott-Knott",
    "section": "Observação",
    "text": "Observação\nÉ preferível fazer as análises exploratórias e verificar as premissas usando os pacotes “performance” e “DHARMa”. O pacote “ExpDes.pt” aplica os testes mais o p-valor, mas não dá os gráficos dos pacotes “performance” e “DHARMa”. Então, deve-se usar os pacotes verificar se os resíduos da ANOVA e a homocedasticidade das amostras estão bons, depois fazer as transformações e depois aplicar o “ExpDes.pt” com a função “dic” para fazer o Scott-Knott. O pacote “ExpDes.pt” é para fazer só o Scott-Knott."
  },
  {
    "objectID": "R_codes/aula2.html",
    "href": "R_codes/aula2.html",
    "title": "Carregar pacotes",
    "section": "",
    "text": "Aula 2\nO carregamento de pacotes pode ser feito pelo menu ou então com um comando no console. O fluxo básico da programação pode ser conferido neste link."
  },
  {
    "objectID": "R_codes/aula2.html#instalar-e-carregar-um-pacote",
    "href": "R_codes/aula2.html#instalar-e-carregar-um-pacote",
    "title": "Carregar pacotes",
    "section": "Instalar e carregar um pacote",
    "text": "Instalar e carregar um pacote\nO tidyverse é uma coleção de pacotes R projetados para ciência de dados. Todos os pacotes compartilham uma filosofia de design subjacente, gramática e estruturas de dados.\nA instalação é feita através do menu: Tools > Install packages.\n\nlibrary(tidyverse)\nlibrary(gsheet)"
  },
  {
    "objectID": "R_codes/aula2.html#invocar-uma-função-de-um-pacote",
    "href": "R_codes/aula2.html#invocar-uma-função-de-um-pacote",
    "title": "Carregar pacotes",
    "section": "Invocar uma função de um pacote",
    "text": "Invocar uma função de um pacote\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\narrange(mtcars, -mpg)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n\n\n\nurl <- 'docs.google.com/spreadsheets/d/1I9mJsS5QnXF2TNNntTy-HrcdHmIF9wJ8ONYvEJTXSNo'\nmtcars <- gsheet2tbl(url)\nhead(mtcars)\n\n# A tibble: 6 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1  21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6   225   105  2.76  3.46  20.2     1     0     3     1"
  },
  {
    "objectID": "R_codes/aula3.html",
    "href": "R_codes/aula3.html",
    "title": "Importar dados",
    "section": "",
    "text": "Aula 3"
  },
  {
    "objectID": "R_codes/aula3.html#de-pacotes",
    "href": "R_codes/aula3.html#de-pacotes",
    "title": "Importar dados",
    "section": "De pacotes",
    "text": "De pacotes\n\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\ncars2 <- cars\nspeed <- cars2"
  },
  {
    "objectID": "R_codes/aula3.html#dataframe-de-pacotes",
    "href": "R_codes/aula3.html#dataframe-de-pacotes",
    "title": "Importar dados",
    "section": "Dataframe de pacotes",
    "text": "Dataframe de pacotes\n\nlibrary(remotes)\nremotes::install_github(\"emdelponte/r4pde\")\nlibrary(\"r4pde\")\ndf <- RustSoybean\ndf\n\n# A tibble: 34 × 7\n   epidemia latitude longitude local              planting   detection  severity\n      <dbl>    <dbl>     <dbl> <chr>              <date>     <date>        <dbl>\n 1       23    -23.0     -50.1 Cambara            2003-11-25 2004-02-02     24  \n 2       24    -24.0     -52.4 Campo Mourao       2003-11-28 2004-02-02     21  \n 3       31    -15.5     -55.2 Campo Verde        2004-11-20 2005-01-25     78  \n 4        3    -13.3     -44.6 Correntina         2002-11-10 2003-01-03     85  \n 5       15    -13.3     -44.6 Correntina         2003-11-28 2004-01-31     25  \n 6       34    -25.4     -51.5 Guarapuava         2004-11-29 2005-03-14     32  \n 7        7    -29.2     -53.7 Julio Castilhos    2002-12-15 2003-04-10     40  \n 8       13    -12.1     -45.8 Luis Eduardo Maga… 2003-11-12 2004-02-15     39.2\n 9       33    -12.1     -45.8 Luis Eduardo Maga… 2004-11-19 2005-01-25     55  \n10        1    -23.3     -51.2 Londrina           2002-11-06 2003-02-03     45  \n# ℹ 24 more rows"
  },
  {
    "objectID": "R_codes/aula3.html#do-excel",
    "href": "R_codes/aula3.html#do-excel",
    "title": "Importar dados",
    "section": "Do excel",
    "text": "Do excel\n\nlibrary(readxl)\nmagnesio <- read_excel(\"dados-diversos.xlsx\")\nescala1 <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nescala2 <- read_excel(\"dados-diversos.xlsx\", 2)"
  },
  {
    "objectID": "R_codes/aula3.html#tabela-com-menu",
    "href": "R_codes/aula3.html#tabela-com-menu",
    "title": "Importar dados",
    "section": "Tabela com menu",
    "text": "Tabela com menu\n\nsurvey <- read_excel(\"dados-diversos.xlsx\", \"survey\")\nlibrary(DT)\ndatatable(survey,\n          extensions = 'Buttons',\n          options = list(\n            dom = 'Bfrtip',\n            buttons = c('copy', 'excel')\n          ))"
  },
  {
    "objectID": "R_codes/aula3.html#de-csv",
    "href": "R_codes/aula3.html#de-csv",
    "title": "Importar dados",
    "section": "De CSV",
    "text": "De CSV\n\nlibrary(tidyverse)\nmagnesio2 <- read.csv(\"dados-diversos.csv\")\nmagnesio3 <- read_csv(\"dados-diversos.csv\")"
  },
  {
    "objectID": "R_codes/aula3.html#de-txt",
    "href": "R_codes/aula3.html#de-txt",
    "title": "Importar dados",
    "section": "De TXT",
    "text": "De TXT\n\nmagnesio4 <- read.table(\"dados-diversos.txt\", sep = ',')"
  },
  {
    "objectID": "R_codes/aula3.html#do-google-sheet",
    "href": "R_codes/aula3.html#do-google-sheet",
    "title": "Importar dados",
    "section": "Do google sheet",
    "text": "Do google sheet\n\nLink da primeira aba\n\n\nLink da segunda aba\n\n\nLink da internet\n\nlibrary(gsheet)\nmagnesio5 <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\nsurvey <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=366054269\")\nfusarium <- read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/fusarium_banana.csv\")"
  },
  {
    "objectID": "R_codes/aula4.html",
    "href": "R_codes/aula4.html",
    "title": "FIP606",
    "section": "",
    "text": "Aula 4"
  },
  {
    "objectID": "R_codes/aula4.html#noções-básicas-de-plotagem",
    "href": "R_codes/aula4.html#noções-básicas-de-plotagem",
    "title": "FIP606",
    "section": "Noções básicas de plotagem",
    "text": "Noções básicas de plotagem\nTodos os gráficos ggplot2 começam com uma chamada para ggplot(), fornecendo dados padrão e mapeamentos estéticos, especificados por aes(). Em seguida, você adiciona camadas, escalas, coordenadas e facetas com +. Para salvar um gráfico em disco, use ggsave().\n\nggplot()\n\nCriar um novo ggplot\n\naes()\n\nConstruir mapeamentos estéticos\n\n`+`(<gg>) |>\n\nAdicionar componentes a um gráfico\n\nggsave()\n\nSalve um ggplot (ou outro objeto de grade) com padrões sensatos\n\nqplot() quickplot()\n\nplotagem rápida\n\n\nPara mais informações sobre o pacote ggplo2, clique aqui."
  },
  {
    "objectID": "R_codes/aula4.html#importar-dados",
    "href": "R_codes/aula4.html#importar-dados",
    "title": "FIP606",
    "section": "Importar dados",
    "text": "Importar dados\n\nlibrary(tidyverse)\nmg <- read_csv(\"dados-diversos.csv\")\n\nmg |> \n  ggplot(aes(Irrigation, severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)"
  },
  {
    "objectID": "R_codes/aula4.html#gerando-gráficos",
    "href": "R_codes/aula4.html#gerando-gráficos",
    "title": "FIP606",
    "section": "Gerando gráficos",
    "text": "Gerando gráficos\n\nmg |> \n# filter(rep == 3) |> \n  ggplot(aes(day, severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)+\n  geom_line()+\n  facet_wrap(~rep)\n\n\n\n\n\nmg2 <- mg |> \n  select(day, rep, severity) |> \n  group_by(day) |> \n  summarize(sev =  mean(severity))\n\n  mg2 |> \n  ggplot(aes(day, sev*100))+\n  geom_point()+\n  geom_line()+\n  ylim(0,100)+\n    labs(x = \"Time (days)\", y = \"Severity (%)\")\n\n\n\n#   Configurar o gráfico\n\n\nmg2 |> \n  ggplot(aes(day, sev*100))+\n  geom_line(color = \"darkorange\")+\n  geom_point(size = 3, \n             color = \"darkorange\")+\n  scale_x_continuous(breaks = c(0,7,14,21,28,35,42,49,56,63))+\n  scale_y_continuous(n.breaks = 5, \n                     limits = c(0,100))+\n    labs(x = \"Time (days)\", \n         y = \"Severity (%)\", \n         title = \"My first ggplot\", \n         subtitle = \"It is beatiful\", \n         caption = \"Source: FIP 606\")+\n#   Configurar o gráfico\n  theme_light()\n\n\n\nggsave(\"figs/myfirstggplot.png\",\n       bg = \"white\",\n       width = 4,\n       height = 3)"
  },
  {
    "objectID": "R_codes/aula4.html#gráfico-de-interação-em-plotly",
    "href": "R_codes/aula4.html#gráfico-de-interação-em-plotly",
    "title": "FIP606",
    "section": "Gráfico de interação em plotly",
    "text": "Gráfico de interação em plotly\n\np <- mg2 |> \n  ggplot(aes(day, sev*100))+\n  geom_line(color = \"darkorange\")+\n  geom_point(size = 3, \n             color = \"darkorange\")+\n  scale_x_continuous(breaks = c(0,7,14,21,28,35,42,49,56,63))+\n  scale_y_continuous(n.breaks = 5, \n                     limits = c(0,100))+\n    labs(x = \"Time (days)\", \n         y = \"Severity (%)\", \n         title = \"My first ggplot\", \n         subtitle = \"It is beatiful\", \n         caption = \"Source: FIP 606\")+\n#   Configurar o gráfico\n  theme_light()\nggsave(\"figs/myfirstggplot.png\",\n       bg = \"white\",\n       width = 4,\n       height = 3)\n\n\np\n\n\n\nlibrary(plotly)\n  ggplotly(p)\n\n\n\n\n#plotly sem usar ggplot\nplot_ly(mg2, x = ~day, y = ~sev, type = 'scatter', mode = 'dots')"
  },
  {
    "objectID": "R_codes/aula5.html",
    "href": "R_codes/aula5.html",
    "title": "Boxplot",
    "section": "",
    "text": "Aula 5"
  },
  {
    "objectID": "R_codes/aula5.html#o-que-é-o-boxplot",
    "href": "R_codes/aula5.html#o-que-é-o-boxplot",
    "title": "Boxplot",
    "section": "O que é o boxplot?",
    "text": "O que é o boxplot?\nO boxplot ou diagrama de caixa é uma ferramenta gráfica que permite visualizar a distribuição e valores discrepantes (outliers) dos dados, fornecendo assim um meio complementar para desenvolver uma perspectiva sobre o caráter dos dados. Além disso, o boxplot também é uma disposição gráfica comparativa.\nAs medidas de estatísticas descritivas como o mínimo, máximo, primeiro quartil, segundo quartil ou mediana e o terceiro quartil formam o boxplot.\nOs quartis são os percentis 25, 50 e 75, representando respectivamente o primeiro, segundo e terceiro quartil. O segundo quartil equivale ao percentil 50, valor em que pelo menos 50% da amostra está acima dele e pelo menos 50% está abaixo. Não é isso a definição de mediana? Sim! O percentil 50 ou segundo quartil equivalem à mediana!\nObserve a figura do boxplot. Note que o local onde a haste vertical começa (de baixo para cima) indica o mínimo (excetuando algum possível valor extremo ou outlier) e, onde a haste termina indica o máximo (também excetuando algum possível outlier).\n\nO retângulo no meio dessa haste possui três linhas horizontais: a linha de baixo, que é o próprio contorno externo inferior do retângulo, indica o primeiro quartil. A de cima, que também é o próprio contorno externo superior do retângulo, indica o terceiro quartil. A linha interna indica o segundo quartil ou mediana.\nOs asteriscos ou pontos que ás vezes aparecem no boxplot indicam que aquelas observações são atípicas, valores discrepantes, extremos ou outliers."
  },
  {
    "objectID": "R_codes/aula5.html#como-interpretar-o-boxplot",
    "href": "R_codes/aula5.html#como-interpretar-o-boxplot",
    "title": "Boxplot",
    "section": "Como interpretar o boxplot?",
    "text": "Como interpretar o boxplot?\nO boxplot nos fornece uma análise visual da posição, dispersão, simetria, caudas e valores discrepantes (outliers) do conjunto de dados.\n\nPosição – Em relação à posição dos dados, observa-se a linha central do retângulo (a mediana ou segundo quartil).\nDispersão – A dispersão dos dados pode ser representada pelo intervalo interquartílico que é a diferença entre o terceiro quartil e o primeiro quartil (tamanho da caixa), ou ainda pela amplitude que é calculada da seguinte maneira: valor máximo – valor mínimo. Embora a amplitude seja de fácil entendimento, o intervalo interquartílico é uma estatística mais robusta para medir variabilidade uma vez que não sofre influência de outliers.\nSimetria – Um conjunto de dados que tem uma distribuição simétrica, terá a linha da mediana no centro do retângulo. Quando a linha da mediana está próxima ao primeiro quartil, os dados são assimétricos positivos e quando a posição da linha da mediana é próxima ao terceiro quartil, os dados são assimétricos negativos. Vale ressaltar que a mediana é a medida de tendência central mais indicada quando os dados possuem distribuição assimétrica, uma vez que a média aritmética é influenciada pelos valores extremos.\nCaudas – As linhas que vão do retângulo até aos outliers podem fornecer o comprimento das caudas da distribuição.\nOutliers – Já os outliers indicam possíveis valores discrepantes. No boxplot, as observações são consideradas outliers quando estão abaixo ou acima do limite de detecção de outliers.\n\nO limite de detecção de outliers é construído utilizando o intervalo interquartílico, dado pela distância entre o primeiro e o terceiro quartil. Sendo assim, os limites inferior e superior de detecção de outlier são dados por:\n\nLimite Inferior = Primeiro Quartil – 1,5 * (Terceiro Quartil – Primeiro Quartil)\nLimite Superior = Terceiro Quartil + 1,5 * (Terceiro Quartil – Primeiro Quartil)"
  },
  {
    "objectID": "R_codes/aula5.html#importar-dados",
    "href": "R_codes/aula5.html#importar-dados",
    "title": "Boxplot",
    "section": "Importar dados",
    "text": "Importar dados\n\nlibrary(tidyverse)\nlibrary(readxl)\nmg <- read_excel(\"dados-diversos.xlsx\")"
  },
  {
    "objectID": "R_codes/aula5.html#visualizar",
    "href": "R_codes/aula5.html#visualizar",
    "title": "Boxplot",
    "section": "Visualizar",
    "text": "Visualizar\n\n### entra no mg, então \np_box <- mg |> ggplot(aes(trat, comp))+\n      #geom_point()+\n      # outlier.color = NA - retirar ponto outline do \n      geom_boxplot(outlier.color = NA,\n                   fill = \"orange\",\n                   size  = 0.5,\n                   width = 0.2)+\n      # para desagregar os pontos\n      geom_jitter(width=0.1,\n                  height = 0,\n                  size = 2,\n                  color = \"steelblue\")+\n      # a escala do y, que é continua, defina os limetes de 5 a 20\n      scale_y_continuous(limits = c(7,19),\n                         n.breaks = 10)+\n      #alterar legenda do eixo Y\n      labs(y = \"Lesion size (mm)\")+\n      labs(x = \"\")+\n      theme_bw()\n#para chamar o objeto criado como p_means\np_box\n\n\n\n#para sarvar em uma pasta dentro do projeto com background (bg) branco\nggsave(\"figs/plot2.png\",\n       width = 4,\n       height = 4,\n       bg = \"white\")\n\n\n#preparar o conjunto para fazer gráfico de barras\nlibrary(ggthemes)\np_means <- mg |>\n  #agrupo por tratamento e sumariza o valor médio do comprimento\n  group_by(trat) |>\n  #cria a variável comp_mean\n  summarise(comp_mean = mean(comp),\n            comp_sd = sd(comp)) |>\n  ggplot(aes(trat, comp_mean))+\n  #geom_col(fill = \"orange\", width = 0.5)+\n  geom_point()+\n  scale_y_continuous(limits = c(7,18),\n                    n.breaks = 6)+\n  #adicionar barra de erro (desvio padrão dos dados originais), estística descritiva\n  geom_errorbar(aes(ymin = comp_mean - comp_sd,\n                    ymax = comp_mean + comp_sd,\n                    width = 0.05))+\n  theme_bw() +\n  labs(y = \"Lesion size (mm)\")+\n      labs(x = \"\")\n#para chamar o objeto criado como p_means\np_means\n\n\n\nggsave(\"figs/mean_sd.png\", \n       width = 4,\n       height = 4,\n       bg = \"white\")\n\n\nlibrary(patchwork)\n\n#(p_box | p_means) / p_box\n\n(p_box | p_means) + \n  plot_annotation(tag_levels = 'A',\n                  title = 'Gráficos que impressionam')\n\n\n\nggsave(\"figs/combined.png\")\n\n\nsurvey <- read_excel(\"dados-diversos.xlsx\", sheet = \"survey\")\n\nsurvey |>\n  #filtra onde estado é igual a RS\n  filter(state == \"RS\") |>\n  count(species,residue) |>\n  ggplot(aes(species,n))+\n  geom_col(width = 0.4,\n           fill = \"steelblue\")+\n  #para girar o gráfico\n  coord_flip()+\n  #ncol para configurar em uma coluna\n  facet_wrap(~residue, ncol = 1)\n\n\n\n  labs (x = \"\",\n        y = \"Number of isolates\",\n        title = \"Horizontal bar plot\",\n        subtitle = \"Using ggplot\")+\n  theme_bw()\n\nNULL\n\nggsave(\"figs/barplot.png\", bg = \"white\")"
  },
  {
    "objectID": "R_codes/aula6.html",
    "href": "R_codes/aula6.html",
    "title": "Gráficos",
    "section": "",
    "text": "Aula 6"
  },
  {
    "objectID": "R_codes/aula6.html#scatter-plot",
    "href": "R_codes/aula6.html#scatter-plot",
    "title": "Gráficos",
    "section": "Scatter plot",
    "text": "Scatter plot\n\nlibrary(tidyverse)\nlibrary(readxl)\nfungicida <- read_excel(\"dados-diversos.xlsx\",\n              \"fungicida_campo\")\n\n\nfungicida |> \n  ggplot(aes(trat, yld))+\n  geom_jitter(width = 0.1, \n              color = \"gray60\")+\n  stat_summary(fun.data  = mean_se, \n               color = \"red\")\n\n\n\n\n\nlibrary(ggthemes)\nfungicida |> \n  ggplot(aes(sev, yld))+\n  geom_point(size = 3, \n             color = \"gray50\")+\n  scale_color_colorblind()+\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              color = \"black\",\n              linetype = \"solid\",\n              size = 1)"
  },
  {
    "objectID": "R_codes/aula6.html#experimento-fatorial",
    "href": "R_codes/aula6.html#experimento-fatorial",
    "title": "Gráficos",
    "section": "Experimento fatorial",
    "text": "Experimento fatorial\n\nmilho <- read_excel(\"dados-diversos.xlsx\",\n                    \"milho\")\n\n\nmilho |> \n  ggplot(aes(method, index,\n             color = method))+\n  geom_jitter(width = 0.1)+\n  facet_grid(~hybrid)"
  },
  {
    "objectID": "R_codes/aula6.html#histograms",
    "href": "R_codes/aula6.html#histograms",
    "title": "Gráficos",
    "section": "Histograms",
    "text": "Histograms\nUtilizado para observar a frequência dos seus dados.\n\ny <- milho |> \n  ggplot(aes(x = yield))+\n  geom_histogram(bins = 10,\n                 color = \"black\", fill = \"green\")\n\ni <- milho |> \n  ggplot(aes(x = index))+\n  geom_histogram(bins = 10,\n                 color = \"black\", fill = \"green\")\n\nlibrary(patchwork)\n(y + i) +\n  plot_annotation(tag_levels = \"A\")\n\n\n\nggsave(\"figs/histograms.png\", bg = \"white\")"
  },
  {
    "objectID": "R_codes/aula6.html#gráfico-de-densidade",
    "href": "R_codes/aula6.html#gráfico-de-densidade",
    "title": "Gráficos",
    "section": "Gráfico de densidade",
    "text": "Gráfico de densidade\n\nmilho |> \n  ggplot(aes(x = yield))+\n  geom_density()"
  },
  {
    "objectID": "R_codes/aula6.html#formato-largo-para-longo",
    "href": "R_codes/aula6.html#formato-largo-para-longo",
    "title": "Gráficos",
    "section": "Formato largo para longo",
    "text": "Formato largo para longo\n\ninsect <- read_excel(\"dados-diversos.xlsx\",\n                   \"mortalidade\")\ninsect |> \n  pivot_longer(2:3, \n               names_to = \"status\",\n               values_to = \"value\") |> \n  ggplot(aes(inseticida, value, \n             fill = status))+\n  geom_col()"
  },
  {
    "objectID": "R_codes/aula6.html#gráfico-de-interação-em-plotly",
    "href": "R_codes/aula6.html#gráfico-de-interação-em-plotly",
    "title": "Gráficos",
    "section": "Gráfico de interação em plotly",
    "text": "Gráfico de interação em plotly\n\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\n\nremotes::install_github(\"emdelponte/r4pde\")\nlibrary(r4pde)\n\nsbr <- RustSoybean\n\nBRA <- ne_states(country = \"Brazil\", \n                    returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\n\nm <- ggplot(BRA) +\ngeom_sf(color = \"black\",\n          fill = \"white\") +\n  geom_point(data = sbr, aes(longitude, latitude), alpha = 0.5)\n\nlibrary(plotly)\n  ggplotly(m)# passe o cursor por cima dos pontos no mapa"
  },
  {
    "objectID": "R_codes/aula7.html",
    "href": "R_codes/aula7.html",
    "title": "Transformar dados",
    "section": "",
    "text": "Aula 7"
  },
  {
    "objectID": "R_codes/aula7.html#histograma",
    "href": "R_codes/aula7.html#histograma",
    "title": "Transformar dados",
    "section": "Histograma",
    "text": "Histograma\n\nh1 <- mofo |> \n  ggplot(aes(x = scl))+\n  geom_histogram(bins = 10)"
  },
  {
    "objectID": "R_codes/aula7.html#boxplot",
    "href": "R_codes/aula7.html#boxplot",
    "title": "Transformar dados",
    "section": "Boxplot",
    "text": "Boxplot\n\ni <- mofo |> \n  ggplot(aes(x = scl))+\n  geom_boxplot(bins = 10)\n  \nlibrary (patchwork)\n(h1 / i)"
  },
  {
    "objectID": "R_codes/aula7.html#média",
    "href": "R_codes/aula7.html#média",
    "title": "Transformar dados",
    "section": "Média",
    "text": "Média\n\n#média \nmean (mofo$scl)\n\n[1] 1639.096\n\n#para cada variável\nsummary(mofo)\n\n     study          treat         inc             scl            yld      \n Min.   :1.00   Min.   : 1   Min.   : 7.00   Min.   : 119   Min.   :1893  \n 1st Qu.:1.75   1st Qu.: 4   1st Qu.:26.00   1st Qu.: 588   1st Qu.:2438  \n Median :2.50   Median : 7   Median :34.00   Median :1337   Median :2678  \n Mean   :2.50   Mean   : 7   Mean   :35.10   Mean   :1639   Mean   :2780  \n 3rd Qu.:3.25   3rd Qu.:10   3rd Qu.:41.25   3rd Qu.:2382   3rd Qu.:3055  \n Max.   :4.00   Max.   :13   Max.   :76.00   Max.   :6216   Max.   :3702  \n\n\n\n#cria um novo conjunto, entra no mofo, então\nmofo2 <- mofo |> \n  #cria a variável scl2, que é igual ao logarítimo (log) do número de escleródios (scl)\n  #mutate(scl2 = log(scl))\n#cria a variável scl2, que é igual a raíz quadrada (sqrt) do número de escleródios (scl)\n  mutate(scl2 = sqrt(scl)) # sqrt é para transformar dados de contagem\nmofo2\n\n# A tibble: 52 × 6\n   study treat   inc   scl   yld  scl2\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1     1    76  2194  2265  46.8\n 2     1     2    53  1663  2618  40.8\n 3     1     3    42  1313  2554  36.2\n 4     1     4    37  1177  2632  34.3\n 5     1     5    29   753  2820  27.4\n 6     1     6    42  1343  2799  36.6\n 7     1     7    55  1519  2503  39.0\n 8     1     8    40   516  2967  22.7\n 9     1     9    26   643  2965  25.4\n10     1    10    18   400  3088  20  \n# ℹ 42 more rows\n\n\n\nh2 <- mofo2 |> \n  ggplot(aes(scl2))+\n  geom_histogram(bins = 10)\nh2\n\n\n\nh1 / h2"
  },
  {
    "objectID": "R_codes/aula7.html#modificar-variáveis",
    "href": "R_codes/aula7.html#modificar-variáveis",
    "title": "Transformar dados",
    "section": "Modificar variáveis",
    "text": "Modificar variáveis\n\n#cria um novo conjunto com a aba survey do arquivo dados-diversos\nsurvey <- read_excel(\"dados-diversos.xlsx\", \"survey\")\n#entra no survey, então\nsurvey |>\n  #filtra por estado\n  filter(state == \"RS\") |>\n  #conta a variável do maior para o menor por padrão\n  count(species, residue) |>\n  #reordena uma coluna, do menor para o maior (n), maior para menor (-n), nome da variável\n  arrange(species) |>\n  #seleciona linhas por posição\n  #slice(1:2) |>\n  #renomear coluna\n  rename(res = residue) |>\n  #cria nova variável segudo uma condição de uma variável anterior\n  mutate(n_class = case_when (\n          n < 30 ~ \"baixa\", \n          TRUE ~ \"Alta\"))\n\n# A tibble: 4 × 4\n  species res         n n_class\n  <chr>   <chr>   <int> <chr>  \n1 Fgra    corn      147 Alta   \n2 Fgra    soybean   255 Alta   \n3 Fspp    corn       22 baixa  \n4 Fspp    soybean    26 baixa"
  },
  {
    "objectID": "R_codes/aula8.html",
    "href": "R_codes/aula8.html",
    "title": "Comparação entre dois grupos",
    "section": "",
    "text": "Aula 8"
  },
  {
    "objectID": "R_codes/aula8.html#tabela-em-formato-largo",
    "href": "R_codes/aula8.html#tabela-em-formato-largo",
    "title": "Comparação entre dois grupos",
    "section": "Tabela em formato largo",
    "text": "Tabela em formato largo\n\n#Para usar o t.test, organizar a tabela no formato largo, um nível do tratamento em uma coluna e outro em outra coluna\nmg2 <- mg |> \n  #pega a coluna 1, ...\n  pivot_wider(1,\n              names_from = trat,\n              values_from = comp)\nmg2\n\n# A tibble: 10 × 3\n     rep   Mg2  Ctrl\n   <dbl> <dbl> <dbl>\n 1     1   9    13.7\n 2     2  12.5  15.9\n 3     3  10    15.7\n 4     4   8    14.2\n 5     5  13.2  15.9\n 6     6  11    16.5\n 7     7  10.8  18  \n 8     8   9.5  14.4\n 9     9  10.8  16.4\n10    10  10.4  16"
  },
  {
    "objectID": "R_codes/aula8.html#teste-t",
    "href": "R_codes/aula8.html#teste-t",
    "title": "Comparação entre dois grupos",
    "section": "Teste t",
    "text": "Teste t\n\n#recebe o grupo mg e depois o grupo controle\n#o $ liga o objeto mg2 a variável Mg2 da tabela no formato longo\nt <- t.test(mg2$Mg2, mg2$Ctrl)\n\n#resultado:df é grau de liberdade"
  },
  {
    "objectID": "R_codes/aula8.html#erro-padrão-da-média-e-resultados",
    "href": "R_codes/aula8.html#erro-padrão-da-média-e-resultados",
    "title": "Comparação entre dois grupos",
    "section": "Erro padrão da média e resultados",
    "text": "Erro padrão da média e resultados\n\nmg |>\n  ggplot(aes(trat, comp))+\n  #erro padrão da média\n  stat_summary(fun.data = \"mean_se\")\n\n\n\nlibrary(report)\n#sugestão para colocar no texto dos resultados\nreport(t)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and mg2$Ctrl\n(mean of x = 10.52, mean of y = 15.68) suggests that the effect is negative,\nstatistically significant, and large (difference = -5.16, 95% CI [-6.49,\n-3.83], t(17.35) = -8.15, p < .001; Cohen's d = -3.65, 95% CI [-5.12, -2.14])\n\nmg |> \n  ggplot(aes(trat, comp))+\n  geom_jitter(width = 0.05)+\n  geom_boxplot(fill = NA,\n               outlier.colour = NA)+\n  ylim(5,20)+\n  annotate(geom = \"text\",\n           x = 0.7, y = 19,\n           label = \" t = 8.12; P < 0.001\")"
  },
  {
    "objectID": "R_codes/aula9.html",
    "href": "R_codes/aula9.html",
    "title": "Amostras dependentes ou pareadas",
    "section": "",
    "text": "Aula 9"
  },
  {
    "objectID": "R_codes/aula9.html#carregar-pacotes",
    "href": "R_codes/aula9.html#carregar-pacotes",
    "title": "Amostras dependentes ou pareadas",
    "section": "Carregar pacotes",
    "text": "Carregar pacotes\n\nlibrary(magrittr) # para usar pipes\nlibrary(ggplot2) # para gráficos\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(tidyr)\n\n\ndata_mg <- read_excel(\"dados-diversos.xlsx\")\nhead(data_mg)\n\n# A tibble: 6 × 3\n  trat    rep  comp\n  <chr> <dbl> <dbl>\n1 Mg2       1   9  \n2 Mg2       2  12.5\n3 Mg2       3  10  \n4 Mg2       4   8  \n5 Mg2       5  13.2\n6 Mg2       6  11  \n\n\n\ndata_mg %>%\n  ggplot(aes(trat, comp)) +\n  geom_boxplot(outlier.color = NA) +\n  geom_jitter(width = 0.1, shape = 1)\n\n\n\n\n\ndat2 <- data_mg |> \n  group_by(trat) |> \n  summarise(\n    mean_comp = mean(comp),\n    sd_comp = sd(comp),\n    var_comp = var(comp),\n    n = n(),\n    se_comp = sd_comp / sqrt(n-1),\n    ci = se_comp * qt(0.025, df = 9)#intervalo de confiança\n    ) \ndat2\n\n# A tibble: 2 × 7\n  trat  mean_comp sd_comp var_comp     n se_comp     ci\n  <chr>     <dbl>   <dbl>    <dbl> <int>   <dbl>  <dbl>\n1 Ctrl       15.7    1.27     1.61    10   0.424 -0.958\n2 Mg2        10.5    1.54     2.39    10   0.515 -1.16 \n\n\n\ndat2 |> \n  ggplot(aes(trat, mean_comp))+\n  geom_col(width = 0.5, fill = \"steelblue\")+\n  geom_errorbar(aes(\n    ymin = mean_comp - ci,\n    ymax = mean_comp + ci), width = 0.1)+\n  ylim(0,20)+\n  labs(x = \"\", y = \"Mean size (mm)\")\n\n\n\n\n\ndata_mg2 <- data_mg |> \n  pivot_wider(1,\n              names_from = trat,\n              values_from = comp)\ndata_mg2\n\n# A tibble: 10 × 3\n     rep   Mg2  Ctrl\n   <dbl> <dbl> <dbl>\n 1     1   9    13.7\n 2     2  12.5  15.9\n 3     3  10    15.7\n 4     4   8    14.2\n 5     5  13.2  15.9\n 6     6  11    16.5\n 7     7  10.8  18  \n 8     8   9.5  14.4\n 9     9  10.8  16.4\n10    10  10.4  16  \n\n\n\nt.test(data_mg2$Mg2, data_mg2$Ctrl, paired = F)\n\n\n    Welch Two Sample t-test\n\ndata:  data_mg2$Mg2 and data_mg2$Ctrl\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\n\nattach(data_mg2) # vamos facilitar o uso dos vetores. Libera no ambiente os objetos\nvar.test(Mg2, Ctrl)\n\n\n    F test to compare two variances\n\ndata:  Mg2 and Ctrl\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111"
  },
  {
    "objectID": "R_codes/aula9.html#normalidade-e-heterocedasticidade",
    "href": "R_codes/aula9.html#normalidade-e-heterocedasticidade",
    "title": "Amostras dependentes ou pareadas",
    "section": "Normalidade e Heterocedasticidade",
    "text": "Normalidade e Heterocedasticidade\n\nshapiro.test(Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Mg2\nW = 0.97269, p-value = 0.9146\n\nshapiro.test(Ctrl)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Ctrl\nW = 0.93886, p-value = 0.5404\n\n\n\nqqnorm(Mg2)\nqqline(Mg2)\n\n\n\nqqnorm(Ctrl)\nqqline(Ctrl)\n\n\n\n\n\nescala <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nhead(escala)\n\n# A tibble: 6 × 7\n  assessment rater acuracia precisao vies_geral vies_sistematico vies_constante\n  <chr>      <chr>    <dbl>    <dbl>      <dbl>            <dbl>          <dbl>\n1 Unaided    A        0.809    0.826      0.979            1.19         0.112  \n2 Unaided    B        0.722    0.728      0.991            0.922       -0.106  \n3 Unaided    C        0.560    0.715      0.783            1.16         0.730  \n4 Unaided    D        0.818    0.819      0.999            0.948       -0.00569\n5 Unaided    E        0.748    0.753      0.993            1.10         0.0719 \n6 Unaided    F        0.695    0.751      0.925            0.802        0.336  \n\nescala2 <- escala |> \n  select(assessment, rater, acuracia)|> \npivot_wider(1,\n            names_from = assessment,\n            values_from = acuracia)\nescala2\n\n# A tibble: 10 × 3\n   rater Unaided Aided1\n   <chr>   <dbl>  <dbl>\n 1 A       0.809  0.907\n 2 B       0.722  0.913\n 3 C       0.560  0.915\n 4 D       0.818  0.960\n 5 E       0.748  0.959\n 6 F       0.695  0.903\n 7 G       0.807  0.851\n 8 H       0.781  0.880\n 9 I       0.776  0.950\n10 J       0.618  0.944"
  },
  {
    "objectID": "R_codes/aula9.html#teste-não-paramétrico",
    "href": "R_codes/aula9.html#teste-não-paramétrico",
    "title": "Amostras dependentes ou pareadas",
    "section": "Teste não paramétrico",
    "text": "Teste não paramétrico\n\nattach(escala2)\nt_escala <- t.test(Aided1, Unaided,\n       paired = TRUE,\n       var.equal = FALSE) # Resultado:  há efeito da escala\n\nvar.test(Aided1,Unaided) # Homocedasticidade\n\n\n    F test to compare two variances\n\ndata:  Aided1 and Unaided\nF = 0.17041, num df = 9, denom df = 9, p-value = 0.01461\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.04232677 0.68605885\nsample estimates:\nratio of variances \n         0.1704073 \n\nshapiro.test(Aided1) # Normalidade. p-value maior que 0,05, então não rejeita H0, logo os valores são homogeneos. \n\n\n    Shapiro-Wilk normality test\n\ndata:  Aided1\nW = 0.92775, p-value = 0.4261\n\nshapiro.test(Unaided) # p-value maior que 0,05, então não rejeita H0, logo os valores são homogeneos.\n\n\n    Shapiro-Wilk normality test\n\ndata:  Unaided\nW = 0.87462, p-value = 0.1131\n\nlibrary(report)\nreport(t_escala)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Paired t-test testing the difference between Aided1 and Unaided (mean\ndifference = 0.18) suggests that the effect is positive, statistically\nsignificant, and large (difference = 0.18, 95% CI [0.11, 0.26], t(9) = 5.94, p\n< .001; Cohen's d = 1.88, 95% CI [0.81, 2.91])\n\nwilcox.test(Aided1, Unaided) # Teste não paramétrico equivalente ao teste t pareado. Utilizar esse teste se houvesse problemas com a normalidade e homocedaticidade.\n\n\n    Wilcoxon rank sum exact test\n\ndata:  Aided1 and Unaided\nW = 100, p-value = 1.083e-05\nalternative hypothesis: true location shift is not equal to 0\n\nescala |> \n  ggplot(aes(assessment, precisao)) +\n  geom_boxplot(outlier.color = NA)"
  },
  {
    "objectID": "R_codes/perfil.html",
    "href": "R_codes/perfil.html",
    "title": "FIP606",
    "section": "",
    "text": "Olá! Feliz em recebê-lo por aqui!\nEu sou Raphael, criador deste site, formado em Agronomia e mestrando em Fitopatologia pela Universidade Federal de Viçosa. Trabalho no Laboratório de Biologia de Populações de Fitopatógenos (BioPop), orientado pelo professor Eduardo S G Mizubuti.\nEspero que as informações do site sejam úteis em suas análises.\nObrigado!"
  },
  {
    "objectID": "R_codes/rrstudio.html",
    "href": "R_codes/rrstudio.html",
    "title": "FIP606",
    "section": "",
    "text": "R é uma linguagem e ambiente para computação estatística e gráficos. É um projeto GNU que é semelhante à linguagem e ambiente S que foi desenvolvido nos Laboratórios Bell (anteriormente AT&T, agora Lucent Technologies) por John Chambers e colegas. R pode ser considerado como uma implementação diferente de S. Existem algumas diferenças importantes, mas muito código escrito para S roda inalterado sob R.\nR fornece uma ampla variedade de técnicas estatísticas (modelagem linear e não linear, testes estatísticos clássicos, análise de séries temporais, classificação, clustering, …) e gráficas, e é altamente extensível. A linguagem S costuma ser o veículo escolhido para pesquisa em metodologia estatística, e R fornece uma rota de código aberto para participação nessa atividade.\nUm dos pontos fortes do R é a facilidade com que gráficos de qualidade de publicação bem projetados podem ser produzidos, incluindo símbolos matemáticos e fórmulas quando necessário. Grande cuidado foi tomado sobre os padrões para as escolhas de design menores em gráficos, mas o usuário mantém o controle total.\nR está disponível como Software Livre sob os termos da Licença Pública Geral GNU da Free Software Foundation em forma de código-fonte. Ele compila e roda em uma ampla variedade de plataformas UNIX e sistemas similares (incluindo FreeBSD e Linux), Windows e MacOS."
  },
  {
    "objectID": "R_codes/rrstudio.html#o-que-é-rstudio",
    "href": "R_codes/rrstudio.html#o-que-é-rstudio",
    "title": "FIP606",
    "section": "O que é RStudio?",
    "text": "O que é RStudio?\nRStudio é um ambiente de desenvolvimento integrado (IDE) para R e Python. Ele inclui um console, editor de realce de sintaxe que oferece suporte à execução direta de código e ferramentas para plotagem, histórico, depuração e gerenciamento de espaço de trabalho. O RStudio está disponível em código aberto e edições comerciais e é executado na área de trabalho (Windows, Mac e Linux).\nPara mais informações sobre o RStudio e download dos programas, visite o site do projeto ."
  }
]